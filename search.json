[
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "practice1",
    "section": "",
    "text": "practice1\n\n\nimport pandas as pd\n\n\nimport matplotlib as mpl\n\n\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\n\n\nfrom pathlib import Path\n\n\nimport pingouin as pg\n\n\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n\n### You don't need to use these settings yourself\n### — they are just here to make the book look nicer!\n# Set the plot style for prettier charts:\n#plt.style.use(\n#    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n#)\n\n\n#Python Walkthrough 1.1\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n\npip install pandas\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (2.2.3)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.2)\nRequirement already satisfied: numpy&gt;=1.22.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n# Python Walkthrough 1.1\nimport pandas as pd  # 导入 Pandas 库\n\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n# 现在您可以使用 df 进行后续的数据处理和分析\n\n\ndf.head()\n\n\n\n\n\n\n\n\nYear\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\n\n\n0\n1880\n-0.39\n-0.54\n-0.24\n-0.31\n-0.05\n-0.18\n-0.23\n-0.27\n-0.26\n-0.31\n-0.46\n-0.43\n-0.31\nNaN\nNaN\n-0.20\n-0.23\n-0.34\n\n\n1\n1881\n-0.31\n-0.26\n-0.07\n-0.03\n0.03\n-0.34\n0.08\n-0.06\n-0.29\n-0.45\n-0.38\n-0.24\n-0.19\n-0.21\n-0.33\n-0.02\n-0.11\n-0.37\n\n\n2\n1882\n0.25\n0.20\n0.01\n-0.31\n-0.24\n-0.29\n-0.28\n-0.17\n-0.26\n-0.53\n-0.34\n-0.69\n-0.22\n-0.18\n0.07\n-0.18\n-0.25\n-0.38\n\n\n3\n1883\n-0.58\n-0.66\n-0.15\n-0.30\n-0.26\n-0.11\n-0.06\n-0.23\n-0.34\n-0.16\n-0.45\n-0.15\n-0.29\n-0.33\n-0.64\n-0.24\n-0.13\n-0.32\n\n\n4\n1884\n-0.17\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.51\n-0.45\n-0.45\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145 entries, 0 to 144\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Year    145 non-null    int64  \n 1   Jan     145 non-null    float64\n 2   Feb     145 non-null    float64\n 3   Mar     145 non-null    float64\n 4   Apr     145 non-null    float64\n 5   May     145 non-null    float64\n 6   Jun     145 non-null    float64\n 7   Jul     145 non-null    float64\n 8   Aug     145 non-null    float64\n 9   Sep     145 non-null    float64\n 10  Oct     145 non-null    float64\n 11  Nov     144 non-null    float64\n 12  Dec     144 non-null    float64\n 13  J-D     144 non-null    float64\n 14  D-N     143 non-null    float64\n 15  DJF     144 non-null    float64\n 16  MAM     145 non-null    float64\n 17  JJA     145 non-null    float64\n 18  SON     144 non-null    float64\ndtypes: float64(18), int64(1)\nmemory usage: 21.6 KB\n\n\n\n#Python Walkthrough 1.2\n\ndf = df.set_index(\"Year\")\ndf.head()\ndf.tail()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020\n1.59\n1.70\n1.67\n1.40\n1.27\n1.14\n1.10\n1.12\n1.19\n1.21\n1.59\n1.19\n1.35\n1.36\n1.56\n1.44\n1.12\n1.33\n\n\n2021\n1.25\n0.96\n1.21\n1.13\n1.05\n1.21\n1.07\n1.03\n1.05\n1.30\n1.29\n1.17\n1.14\n1.14\n1.13\n1.13\n1.10\n1.21\n\n\n2022\n1.25\n1.17\n1.41\n1.09\n1.02\n1.13\n1.06\n1.17\n1.15\n1.31\n1.10\n1.06\n1.16\n1.17\n1.19\n1.17\n1.12\n1.19\n\n\n2023\n1.30\n1.30\n1.64\n1.02\n1.13\n1.19\n1.45\n1.57\n1.67\n1.88\n1.98\n1.85\n1.50\n1.43\n1.22\n1.26\n1.40\n1.84\n\n\n2024\n1.68\n1.93\n1.78\n1.80\n1.45\n1.54\n1.42\n1.42\n1.58\n1.72\nNaN\nNaN\nNaN\nNaN\n1.82\n1.67\n1.46\nNaN\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\ndf[\"Jan\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\npip install matplotlib\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\lib\\site-packages (3.7.0)\nRequirement already satisfied: numpy&gt;=1.20 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\nRequirement already satisfied: packaging&gt;=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: cycler&gt;=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: fonttools&gt;=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: contourpy&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\nRequirement already satisfied: six&gt;=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n# 导入 Matplotlib 的 pyplot 模块\nimport matplotlib.pyplot as plt\n\n# 创建图形和轴对象\nfig, ax = plt.subplots()\n\n# 假设 df 是已经定义好的 DataFrame，并且包含名为 \"Jan\" 的列\n# 注意：这里假设的代码没有显示 df 的定义和加载，您需要确保这部分已经正确完成\ndf[\"Jan\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\n\n# 显示图形\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\")\n\nText(0, 0.5, 'Annual temperature anomalies')\n\n\n\n\n\n\n\n\n\n\n#Python Walkthrough 1.3\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\")\n\nText(0, 0.5, 'Annual temperature anomalies')\n\n\n\n\n\n\n\n\n\n\n#Python Walkthrough 1.4\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n\n\ndf[\"Period\"].tail(20)\n\nYear\n2005    1981—2010\n2006    1981—2010\n2007    1981—2010\n2008    1981—2010\n2009    1981—2010\n2010    1981—2010\n2011          NaN\n2012          NaN\n2013          NaN\n2014          NaN\n2015          NaN\n2016          NaN\n2017          NaN\n2018          NaN\n2019          NaN\n2020          NaN\n2021          NaN\n2022          NaN\n2023          NaN\n2024          NaN\nName: Period, dtype: category\nCategories (3, object): ['1921—1950' &lt; '1951—1980' &lt; '1981—2010']\n\n\n\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\n\nYear     \n1880  Jun   -0.18\n      Jul   -0.23\n      Aug   -0.27\n1881  Jun   -0.34\n      Jul    0.08\ndtype: float64\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n#Python Walkthrough 1.5\n# Create a variable that has years 1951 to 1980, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at this data:\ntemp_all_months\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1951\nJan\n-0.36\n\n\n1\n1951\nFeb\n-0.51\n\n\n2\n1951\nMar\n-0.18\n\n\n3\n1951\nApr\n0.06\n\n\n4\n1951\nMay\n0.17\n\n\n...\n...\n...\n...\n\n\n355\n1980\nAug\n0.10\n\n\n356\n1980\nSep\n0.10\n\n\n357\n1980\nOct\n0.12\n\n\n358\n1980\nNov\n0.21\n\n\n359\n1980\nDec\n0.09\n\n\n\n\n360 rows × 3 columns\n\n\n\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is 17.099999999999998\nThe hot threshold of 70.0% is 25.9\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# 假设的 DataFrame，其中包含温度数据\ndata = {\n    \"values\": [10, 12, 15, 18, 20, 22, 25, 28, 30, 32]  # 示例温度数据\n}\ntemp_all_months = pd.DataFrame(data)\n\n# 定义分位数\nquantiles = [0.3, 0.7]\n\n# 计算给定分位数的值\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\n# 打印结果\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is 17.099999999999998\nThe hot threshold of 70.0% is 25.9\n\n\n\n#Python Walkthrough 1.6\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1981\nJan\n0.80\n\n\n1\n1981\nFeb\n0.62\n\n\n2\n1981\nMar\n0.68\n\n\n3\n1981\nApr\n0.39\n\n\n4\n1981\nMay\n0.18\n\n\n\n\n\n\n\n\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\n\nThe proportion under 17.099999999999998 is 100.00%\n\n\n\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\nThe proportion over 25.9 is 0.00%\n\n\n\n#Python Walkthrough 1.7\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"season\", 0: \"values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\n\n\n\n\n\n\n\n\nYear\nseason\nvalues\nPeriod\n\n\n\n\n443\n1991\nDJF\n0.51\n1981—2010\n\n\n444\n1991\nMAM\n0.45\n1981—2010\n\n\n445\n1991\nJJA\n0.42\n1981—2010\n\n\n446\n1991\nSON\n0.32\n1981—2010\n\n\n447\n1992\nDJF\n0.44\n1981—2010\n\n\n448\n1992\nMAM\n0.30\n1981—2010\n\n\n449\n1992\nJJA\n-0.04\n1981—2010\n\n\n450\n1992\nSON\n-0.15\n1981—2010\n\n\n451\n1993\nDJF\n0.37\n1981—2010\n\n\n452\n1993\nMAM\n0.31\n1981—2010\n\n\n\n\n\n\n\n\ngrp_mean_var = temp_all_months.groupby([\"season\", \"Period\"])[\"values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\nseason\nPeriod\n\n\n\n\n\n\nDJF\n1921—1950\n-0.026207\n0.057303\n\n\n1951—1980\n-0.002333\n0.050494\n\n\n1981—2010\n0.524333\n0.079646\n\n\nJJA\n1921—1950\n-0.052414\n0.021290\n\n\n1951—1980\n-0.000333\n0.014631\n\n\n1981—2010\n0.400333\n0.067727\n\n\nMAM\n1921—1950\n-0.041724\n0.031236\n\n\n1951—1980\n0.000333\n0.025245\n\n\n1981—2010\n0.510333\n0.076238\n\n\nSON\n1921—1950\n0.083103\n0.027751\n\n\n1951—1980\n-0.001000\n0.026258\n\n\n1981—2010\n0.429333\n0.111731\n\n\n\n\n\n\n\n\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"values\", color=\"season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n            \n            \n              \n                \n                  \n                    1951—1980 average\n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1880\n              \n            \n          \n          \n            \n            \n            \n              \n                1900\n              \n            \n          \n          \n            \n            \n            \n              \n                1920\n              \n            \n          \n          \n            \n            \n            \n              \n                1940\n              \n            \n          \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2020\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -1.0\n              \n            \n          \n          \n            \n              \n                -0.5\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.5\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n          \n            \n              \n                1.5\n              \n            \n          \n        \n      \n    \n    \n      \n        Average annual temperature anomaly in \n      \n      \n         in the northern hemisphere (1880—2024)\n      \n    \n    \n      \n        Annual temperature anomalies\n      \n    \n    \n      \n        Year\n      \n    \n    \n      \n      \n      \n        \n          \n            season\n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                MAM\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                JJA\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                SON\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                DJF\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\n#Python Walkthrough 1.8\ndf_co2 = pd.read_csv(\"C:\\Users\\llll\\Desktop\\xujin homework\\practice\\1_CO2-data.csv\")\ndf_co2.head()\n\n\n  Cell In[51], line 2\n    df_co2 = pd.read_csv(\"C:\\Users\\llll\\Desktop\\xujin homework\\practice\\1_CO2-data.csv\")\n                                                                                       ^\nSyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n\n\n\n\n\ndf_co2 = pd.read_csv(\"C:/Users/llll/Desktop/xujin homework/practice/1_CO2-data.csv\")\n\n\ndf_co2.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n0\n1958\n3\n315.71\n315.71\n314.62\n\n\n1\n1958\n4\n317.45\n317.45\n315.29\n\n\n2\n1958\n5\n317.50\n317.50\n314.71\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n4\n1958\n7\n315.86\n315.86\n314.98\n\n\n\n\n\n\n\n\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n15\n1959\n6\n318.15\n318.15\n315.92\n\n\n27\n1960\n6\n319.59\n319.59\n317.36\n\n\n39\n1961\n6\n319.77\n319.77\n317.48\n\n\n51\n1962\n6\n320.55\n320.55\n318.27\n\n\n\n\n\n\n\n\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n\n\n\n\n\n\n\n\nYear\nJun\nTrend\n\n\n\n\n0\n1958\n0.05\n314.85\n\n\n1\n1959\n0.14\n315.92\n\n\n2\n1960\n0.18\n317.36\n\n\n3\n1961\n0.18\n317.48\n\n\n4\n1962\n-0.13\n318.27\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.0\n              \n            \n          \n          \n            \n            \n            \n              \n                0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.4\n              \n            \n          \n          \n            \n            \n            \n              \n                0.6\n              \n            \n          \n          \n            \n            \n            \n              \n                0.8\n              \n            \n          \n          \n            \n            \n            \n              \n                1.0\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                320\n              \n            \n          \n          \n            \n              \n                340\n              \n            \n          \n          \n            \n              \n                360\n              \n            \n          \n          \n            \n              \n                380\n              \n            \n          \n          \n            \n              \n                400\n              \n            \n          \n        \n      \n    \n    \n      \n        Scatterplot of temperature anomalies vs carbon dioxide emissions\n      \n    \n    \n      \n        Carbon dioxide levels (trend, mole fraction)\n      \n    \n    \n      \n        Temperature anomaly (degrees Celsius)\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n\n\n\n\n\n\n\n\nJun\nTrend\n\n\n\n\nJun\n1.00000\n0.91495\n\n\nTrend\n0.91495\n1.00000\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.2\n              \n            \n          \n          \n            \n              \n                0.4\n              \n            \n          \n          \n            \n              \n                0.6\n              \n            \n          \n          \n            \n              \n                0.8\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n        \n      \n    \n    \n      \n        June temperature anomalies\n      \n    \n    \n      \n        Jun\n      \n    \n    \n      \n        Year\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n\n\n  \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  -0.2\n                \n              \n            \n            \n              \n                \n                  0.0\n                \n              \n            \n            \n              \n                \n                  0.2\n                \n              \n            \n            \n              \n                \n                  0.4\n                \n              \n            \n            \n              \n                \n                  0.6\n                \n              \n            \n            \n              \n                \n                  0.8\n                \n              \n            \n            \n              \n                \n                  1.0\n                \n              \n            \n          \n        \n      \n      \n        \n          June temperature anomalies\n        \n      \n      \n        \n          Jun\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  320\n                \n              \n            \n            \n              \n                \n                  340\n                \n              \n            \n            \n              \n                \n                  360\n                \n              \n            \n            \n              \n                \n                  380\n                \n              \n            \n            \n              \n                \n                  400\n                \n              \n            \n          \n        \n      \n      \n        \n          Carbon dioxide emissions\n        \n      \n      \n        \n          Trend\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n\n\n\nSource: You don't need to use these settings yourself\n\n\npractice2\n\n\nimport pandas as pd\n\n\nimport matplotlib as mpl\n\n\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\n\n\nfrom pathlib import Path\n\n\nimport pingouin as pg\n\n\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\nfile_path = '游戏.xlsx'\ndf = pd.read_excel(file_path, header=1)\n\n\ndf.columns = df.columns.str.strip()\n\n\nfile_path = '游戏.xlsx'\ndf = pd.read_excel(file_path, header=0)\n\n\ndf.columns = ['Round_Label', 'Round_10', 'Round_9', 'Round_8', 'Round_7', 'Round_6', 'Round_5', 'Round_4', 'Round_3', 'Round_2', 'Round_1']\nround_data = df.iloc[1, 1:]\nround_numbers = list(range(1, 11))\n\n\navg_contribution_df = pd.DataFrame({\n    'Round': round_numbers,\n    'Average Contribution': round_data.values\n})\n\n\nplt.figure(figsize=(10, 6))\nplt.plot(avg_contribution_df['Round'], avg_contribution_df['Average Contribution'], marker='o', linestyle='-', color='b')\nplt.title('Average Contribution Over Rounds')\nplt.xlabel('Round')\nplt.ylabel('Average Contribution')\nplt.grid(True)\nplt.xticks(round_numbers)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\navg_contribution_description = f\"\"\"\nAverage contributions have varied across the 10 rounds of the game. Here are the key observations:\n- Round 1: {avg_contribution_df.loc[avg_contribution_df['Round'] == 1, 'Average Contribution'].values[0]}\n- Round 10: {avg_contribution_df.loc[avg_contribution_df['Round'] == 10, 'Average Contribution'].values[0]}\n- Highest Average Contribution: {avg_contribution_df['Average Contribution'].max()} (Round {avg_contribution_df['Average Contribution'].idxmax() + 1})\n- Lowest Average Contribution: {avg_contribution_df['Average Contribution'].min()} (Round {avg_contribution_df['Average Contribution'].idxmin() + 1})\n\"\"\"\nprint(avg_contribution_description)\nplt.show()\n\n\nAverage contributions have varied across the 10 rounds of the game. Here are the key observations:\n- Round 1: 53.4\n- Round 10: 50\n- Highest Average Contribution: 58.4 (Round 9)\n- Lowest Average Contribution: 44.3 (Round 6)\n\n\n\n\n# Create a dictionary with the data in\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()\n\n\n\n\n\n\n\n\nCopenhagen\nDniprop\nMinsk\n\n\n\n\n0\n14.1\n11.0\n12.8\n\n\n1\n14.1\n12.6\n12.3\n\n\n2\n13.7\n12.1\n12.6\n\n\n3\n12.9\n11.2\n12.3\n\n\n4\n12.3\n11.3\n11.8\n\n\n\n\n\n\n\n\n# Plot the data\nfig, ax = plt.subplots()\ndf.plot(ax=ax)\nax.set_title(\"Average contributions to the public goods game: Without punishment\")\nax.set_ylabel(\"Average contribution\")\nax.set_xlabel(\"Round\");\n\n\n\n\n\n\n\n\n\nimport pandas as pd\n\n\nfile_path = \"doing-economics-datafile-working-in-excel-project-2.xlsx\"\n\n\nwithout_punishment = pd.read_excel(file_path, sheet_name=0, skiprows=1, nrows=10, usecols=\"B:Q\")\nwithout_punishment['Mean Contribution (Without Punishment)'] = without_punishment.mean(axis=1)\n\n\nwith_punishment = pd.read_excel(file_path, sheet_name=0, skiprows=28, nrows=10, usecols=\"B:Q\")\nwith_punishment['Mean Contribution (With Punishment)'] = with_punishment.mean(axis=1)\n\n\nprint(\"Mean Contributions Without Punishment:\")\nprint(without_punishment[['Mean Contribution (Without Punishment)']])\n\nprint(\"\\nMean Contributions With Punishment:\")\nprint(with_punishment[['Mean Contribution (With Punishment)']])\n\nMean Contributions Without Punishment:\n   Mean Contribution (Without Punishment)\n0                               10.578313\n1                               10.628398\n2                               10.407079\n3                                9.813033\n4                                9.305433\n5                                8.454844\n6                                7.837568\n7                                7.376388\n8                                6.392985\n9                                4.383769\n\nMean Contributions With Punishment:\nEmpty DataFrame\nColumns: [Mean Contribution (With Punishment)]\nIndex: []\n\n\n\npip install pandas matplotlib openpyxl\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (2.2.3)\nRequirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\lib\\site-packages (3.7.0)\nRequirement already satisfied: openpyxl in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (3.1.5)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.2)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\nRequirement already satisfied: numpy&gt;=1.22.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: fonttools&gt;=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: pillow&gt;=6.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\nRequirement already satisfied: cycler&gt;=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\nRequirement already satisfied: packaging&gt;=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\nRequirement already satisfied: et-xmlfile in d:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\nRequirement already satisfied: six&gt;=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfile_path = 'doing-economics-datafile-working-in-excel-project-2.xlsx'\ndf = pd.read_excel(file_path, sheet_name=None)\n\n\nwithout_punishment = pd.DataFrame()\nwith_punishment = pd.DataFrame()\n\n\nfor sheet_name, data in df.items():\n    if 'without punishment' in sheet_name.lower():\n        data = data.iloc[2:]\n\n\nfor sheet_name, data in df.items():\n    if 'without punishment' in sheet_name.lower():\n        data = data.iloc[2:]\n        mean_contributions = data.iloc[:, 1:].mean(axis=1)  \n        mean_contributions['Period'] = range(1, len(mean_contributions) + 1)\n        mean_contributions.set_index('Period', inplace=True)\n        mean_contributions.rename(columns={0: 'Mean Contribution'}, inplace=True)\n        if without_punishment.empty:\n            without_punishment = mean_contributions.copy()\n        else:\n            without_punishment = pd.concat([without_punishment, mean_contributions], ignore_index=True)\n            \n    elif 'with punishment' in sheet_name.lower():\n        data = data.iloc[2:]\n        mean_contributions = data.iloc[:, 1:].mean(axis=1)\n        mean_contributions['Period'] = range(1, len(mean_contributions) + 1)\n        mean_contributions.set_index('Period', inplace=True)\n        mean_contributions.rename(columns={0: 'Mean Contribution'}, inplace=True)\n        \n        if with_punishment.empty:\n            with_punishment = mean_contributions.copy()\n        else:\n            with_punishment = pd.concat([with_punishment, mean_contributions], ignore_index=True)\n\n\nimport pandas as pd\n\ndata_np = pd.read_excel(\n    'C:/Users/llll/Desktop/xujin homework/practice/doing-economics-datafile-working-in-excel-project-2.xlsx',\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\n\n\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\n\n\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\n\n\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\n\ntest_df=\n   City A  City B\n0    14.1    11.0\n1    14.1    99.0\n2    13.7    12.1\n\ntest_copy=\n   City A  City B\n0    14.1    11.0\n1    14.1    12.6\n2    13.7    12.1\n\n\n\n\ndata_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 10 entries, 1 to 10\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   Copenhagen       10 non-null     object\n 1   Dnipropetrovs’k  10 non-null     object\n 2   Minsk            10 non-null     object\n 3   St. Gallen       10 non-null     object\n 4   Muscat           10 non-null     object\n 5   Samara           10 non-null     object\n 6   Zurich           10 non-null     object\n 7   Boston           10 non-null     object\n 8   Bonn             10 non-null     object\n 9   Chengdu          10 non-null     object\n 10  Seoul            10 non-null     object\n 11  Riyadh           10 non-null     object\n 12  Nottingham       10 non-null     object\n 13  Athens           10 non-null     object\n 14  Istanbul         10 non-null     object\n 15  Melbourne        10 non-null     object\ndtypes: object(16)\nmemory usage: 1.3+ KB\n\n\n\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")\n\n\n# 使用 pd.to_numeric 转换，将无法转换的值设置为 NaN\ndata_n = data_n.apply(pd.to_numeric, errors='coerce')\ndata_p = data_p.apply(pd.to_numeric, errors='coerce')\n\n# 检查数据类型\nprint(data_n.dtypes)\nprint(data_p.dtypes)\n\nCopenhagen         float64\nDnipropetrovs’k    float64\nMinsk              float64\nSt. Gallen         float64\nMuscat             float64\nSamara             float64\nZurich             float64\nBoston             float64\nBonn               float64\nChengdu            float64\nSeoul              float64\nRiyadh             float64\nNottingham         float64\nAthens             float64\nIstanbul           float64\nMelbourne          float64\ndtype: object\nCopenhagen         float64\nDnipropetrovs’k    float64\nMinsk              float64\nSt. Gallen         float64\nMuscat             float64\nSamara             float64\nZurich             float64\nBoston             float64\nBonn               float64\nChengdu            float64\nSeoul              float64\nRiyadh             float64\nNottingham         float64\nAthens             float64\nIstanbul           float64\nMelbourne          float64\ndtype: object\n\n\n\nimport numpy as np\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\n\n\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();\n\n\n\n\n\n\n\n\n\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);\n\n\n\n\n\n\n\n\n\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\n\n\n\n\n\n\n\n\nstd\nvar\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n1\n2.020724\n4.083325\n10.578313\n\n\n2\n2.238129\n5.009220\n10.628398\n\n\n3\n2.329569\n5.426891\n10.407079\n\n\n4\n2.068213\n4.277504\n9.813033\n\n\n5\n2.108329\n4.445049\n9.305433\n\n\n6\n2.240881\n5.021549\n8.454844\n\n\n7\n2.136614\n4.565117\n7.837568\n\n\n8\n2.349442\n5.519880\n7.376388\n\n\n9\n2.413845\n5.826645\n6.392985\n\n\n10\n2.187126\n4.783520\n4.383769\n\n\n\n\n\n\n\n\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\n\n\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n\nPeriod\n1     10.199675\n2     12.185065\n3     12.689935\n4     12.625000\n5     12.140375\n6     12.827541\n7     13.098931\n8     13.482621\n9     13.496754\n10    11.307360\ndtype: float64\n\n\n\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\n\n50\n\n\n\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\n\n\nsumm_n.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n6.14\n14.10\n7.96\n2.02\n10.58\n\n\n10\n7.38\n8.68\n1.30\n2.19\n4.38\n\n\n\n\n\n\n\n\nsumm_p.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n10.20\n16.02\n5.82\n3.21\n10.64\n\n\n10\n11.31\n17.51\n6.20\n3.90\n12.87\n\n\n\n\n\n\n\n\nimport pingouin as pg\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.063782\n30\ntwo-sided\n0.949567\n[-2.0, 1.87]\n0.02255\n0.337\n0.050437\n\n\n\n\n\n\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.149959\n15\ntwo-sided\n0.882795\n[-0.92, 0.8]\n0.02255\n0.258\n0.05082\n\n\n\n\n\n\n\n\n# 创建一个包含索引1到11的新索引\nnew_index = range(1, 12)\n# 重新索引DataFrame，包括不存在的索引10\nreindexed_summ_n = summ_n.reindex(new_index)\n# 现在您可以安全地访问索引10（尽管它的值将是NaN）\nprint(reindexed_summ_n.loc[10, :].round(2))\n\nrange    7.38\nmax      8.68\nmin      1.30\nstd      2.19\nmean     4.38\nName: 10, dtype: float64\n\n\nSource: Create a dictionary with the data in\n\n\npractice3\n\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\n\n\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\n\n\n\n\n\n\n\n\nrownames\nname\nyear\nmonth\nday\nhour\nlat\nlong\nstatus\ncategory\nwind\npressure\ntropicalstorm_force_diameter\nhurricane_force_diameter\n\n\n\n\n0\n1\nAmy\n1975\n6\n27\n0\n27.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n1\n2\nAmy\n1975\n6\n27\n6\n28.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n2\n3\nAmy\n1975\n6\n27\n12\n29.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n3\n4\nAmy\n1975\n6\n27\n18\n30.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n4\n5\nAmy\n1975\n6\n28\n0\n31.5\n-78.8\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n5\n6\nAmy\n1975\n6\n28\n6\n32.4\n-78.7\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n6\n7\nAmy\n1975\n6\n28\n12\n33.3\n-78.0\ntropical depression\nNaN\n25\n1011\nNaN\nNaN\n\n\n7\n8\nAmy\n1975\n6\n28\n18\n34.0\n-77.0\ntropical depression\nNaN\n30\n1006\nNaN\nNaN\n\n\n8\n9\nAmy\n1975\n6\n29\n0\n34.4\n-75.8\ntropical storm\nNaN\n35\n1004\nNaN\nNaN\n\n\n9\n10\nAmy\n1975\n6\n29\n6\n34.0\n-74.8\ntropical storm\nNaN\n40\n1002\nNaN\nNaN\n\n\n\n\n\n\n\n\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\n\n'&lt;!DOCTYPE html&gt;\\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"&gt;&lt;head&gt;\\n\\n&lt;meta charset=\"utf-8\"&gt;\\n&lt;meta name=\"generator\" content=\"quarto-1.5.56\"&gt;\\n\\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\"&gt;\\n\\n&lt;meta name=\"author\" content=\"Arthur Turrell\"&gt;\\n'\n\n\n\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n\n       &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=gender pay gap\"&gt;\n            gender pay gap\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=labour\"&gt;\n            labour\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=text analysis\"&gt;\n            text analysis\n           &lt;/a&gt;\n          &lt;/div&gt;\n         &lt;/div&gt;\n         &lt;div class=\"project-details-listing\n\n\n\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\n\n&lt;p&gt;Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" &lt;i&gt;Environment and Planning B: Urban Analytics and City Science&lt;/i&gt; (2024): 23998083241267331. doi: &lt;a href=\"https://doi.org/10.1177/23998083241267331\"&gt;&lt;code&gt;10.1177/23998083241267331&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n\n\nall_paras[1].text\n\n'Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331'\n\n\n\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\n\n['Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331',\n 'Kalamara, Eleni, Arthur Turrell, Chris Redl, George Kapetanios, and Sujit Kapadia. \"Making text count: economic forecasting using newspaper text.\" Journal of Applied Econometrics 37, no. 5 (2022): 896-919. doi: 10.1002/jae.2907',\n 'Turrell, A., Speigner, B., Copple, D., Djumalieva, J. and Thurgood, J., 2021. Is the UK’s productivity puzzle mostly driven by occupational mismatch? An analysis using big data on job vacancies. Labour Economics, 71, p.102013. doi: 10.1016/j.labeco.2021.102013',\n 'Haldane, Andrew G., and Arthur E. Turrell. \"Drawing on different disciplines: macroeconomic agent-based models.\" Journal of Evolutionary Economics 29 (2019): 39-66. doi: 10.1007/s00191-018-0557-5']\n\n\n\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\n\n\n\n\n\n\n\n\nYears\nHosts\nWinners\nScore\nRunner's-up\nThird place\nScore.1\nFourth place\n\n\n\n\n0\n1930 Details\nUruguay\nUruguay\n4 - 2\nArgentina\nUnited States\n[note 1]\nYugoslavia\n\n\n1\n1934 Details\nItaly\nItaly\n2 - 1\nCzechoslovakia\nGermany\n3 - 2\nAustria\n\n\n2\n1938 Details\nFrance\nItaly\n4 - 2\nHungary\nBrazil\n4 - 2\nSweden\n\n\n3\n1950 Details\nBrazil\nUruguay\n2 - 1\nBrazil\nSweden\n[note 2]\nSpain\n\n\n4\n1954 Details\nSwitzerland\nWest Germany\n3 - 2\nHungary\nAustria\n3 - 1\nUruguay\n\n\n\n\n\n\n\n\n%pip install pdftotext\n\nDefaulting to user installation because normal site-packages is not writeable\nCollecting pdftotext\n  Downloading pdftotext-3.0.0.tar.gz (113 kB)\n     ------------------------------------ 113.6/113.6 kB 264.9 kB/s eta 0:00:00\n  Installing build dependencies: started\n  Installing build dependencies: still running...\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nBuilding wheels for collected packages: pdftotext\n  Building wheel for pdftotext (pyproject.toml): started\n  Building wheel for pdftotext (pyproject.toml): finished with status 'error'\nFailed to build pdftotext\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n\n\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\n\n\nmovies = soup.select('td.titleColumn')\ncrew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\nratings = [b.attrs.get('data-value')\n        for b in soup.select('td.posterColumn span[name=ir]')]\n\n\n# create a empty list for storing\n# movie information\nlist = []\n\n# Iterating over movies to extract\n# each movie's details\nfor index in range(0, len(movies)):\n    \n    # Separating movie into: 'place',\n    # 'title', 'year'\n    movie_string = movies[index].get_text()\n    movie = (' '.join(movie_string.split()).replace('.', ''))\n    movie_title = movie[len(str(index))+1:-7]\n    year = re.search('\\((.*?)\\)', movie_string).group(1)\n    place = movie[:len(str(index))-(len(movie))]\n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index],\n            \"year\": year,\n            \"star_cast\": crew[index],\n            }\n    list.append(data)\n\n\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['star_cast'], movie['rating'])\n\n\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\n\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\n\n%pip install requests\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: requests in d:\\programdata\\anaconda3\\lib\\site-packages (2.28.1)\nRequirement already satisfied: charset-normalizer&lt;3,&gt;=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n%pip install beautifulsoup4\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: beautifulsoup4 in d:\\programdata\\anaconda3\\lib\\site-packages (4.11.1)\nRequirement already satisfied: soupsieve&gt;1.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport requests\n \n# 定义请求的 URL 和 headers\nurl = \"https://movie.douban.com/top250\"\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n\n\nfrom bs4 import BeautifulSoup\n\n\nimport csv\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n\n\nimport csv\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n\nSource: Get all paragraphs\n\n\npractice4-1\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0\n\n\nSource: Regular expressions to extract information\n\n\npractice4-2\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0\n\n\nSource: Regular expressions to extract information"
  },
  {
    "objectID": "labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets.html",
    "href": "labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0"
  },
  {
    "objectID": "labs/Practice/practice-3xujin.html",
    "href": "labs/Practice/practice-3xujin.html",
    "title": "",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\n\n\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\n\n\n\n\n\n\n\n\nrownames\nname\nyear\nmonth\nday\nhour\nlat\nlong\nstatus\ncategory\nwind\npressure\ntropicalstorm_force_diameter\nhurricane_force_diameter\n\n\n\n\n0\n1\nAmy\n1975\n6\n27\n0\n27.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n1\n2\nAmy\n1975\n6\n27\n6\n28.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n2\n3\nAmy\n1975\n6\n27\n12\n29.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n3\n4\nAmy\n1975\n6\n27\n18\n30.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n4\n5\nAmy\n1975\n6\n28\n0\n31.5\n-78.8\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n5\n6\nAmy\n1975\n6\n28\n6\n32.4\n-78.7\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n6\n7\nAmy\n1975\n6\n28\n12\n33.3\n-78.0\ntropical depression\nNaN\n25\n1011\nNaN\nNaN\n\n\n7\n8\nAmy\n1975\n6\n28\n18\n34.0\n-77.0\ntropical depression\nNaN\n30\n1006\nNaN\nNaN\n\n\n8\n9\nAmy\n1975\n6\n29\n0\n34.4\n-75.8\ntropical storm\nNaN\n35\n1004\nNaN\nNaN\n\n\n9\n10\nAmy\n1975\n6\n29\n6\n34.0\n-74.8\ntropical storm\nNaN\n40\n1002\nNaN\nNaN\n\n\n\n\n\n\n\n\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\n\n'&lt;!DOCTYPE html&gt;\\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"&gt;&lt;head&gt;\\n\\n&lt;meta charset=\"utf-8\"&gt;\\n&lt;meta name=\"generator\" content=\"quarto-1.5.56\"&gt;\\n\\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\"&gt;\\n\\n&lt;meta name=\"author\" content=\"Arthur Turrell\"&gt;\\n'\n\n\n\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n\n       &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=gender pay gap\"&gt;\n            gender pay gap\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=labour\"&gt;\n            labour\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=text analysis\"&gt;\n            text analysis\n           &lt;/a&gt;\n          &lt;/div&gt;\n         &lt;/div&gt;\n         &lt;div class=\"project-details-listing\n\n\n\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\n\n&lt;p&gt;Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" &lt;i&gt;Environment and Planning B: Urban Analytics and City Science&lt;/i&gt; (2024): 23998083241267331. doi: &lt;a href=\"https://doi.org/10.1177/23998083241267331\"&gt;&lt;code&gt;10.1177/23998083241267331&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n\n\nall_paras[1].text\n\n'Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331'\n\n\n\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\n\n['Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331',\n 'Kalamara, Eleni, Arthur Turrell, Chris Redl, George Kapetanios, and Sujit Kapadia. \"Making text count: economic forecasting using newspaper text.\" Journal of Applied Econometrics 37, no. 5 (2022): 896-919. doi: 10.1002/jae.2907',\n 'Turrell, A., Speigner, B., Copple, D., Djumalieva, J. and Thurgood, J., 2021. Is the UK’s productivity puzzle mostly driven by occupational mismatch? An analysis using big data on job vacancies. Labour Economics, 71, p.102013. doi: 10.1016/j.labeco.2021.102013',\n 'Haldane, Andrew G., and Arthur E. Turrell. \"Drawing on different disciplines: macroeconomic agent-based models.\" Journal of Evolutionary Economics 29 (2019): 39-66. doi: 10.1007/s00191-018-0557-5']\n\n\n\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\n\n\n\n\n\n\n\n\nYears\nHosts\nWinners\nScore\nRunner's-up\nThird place\nScore.1\nFourth place\n\n\n\n\n0\n1930 Details\nUruguay\nUruguay\n4 - 2\nArgentina\nUnited States\n[note 1]\nYugoslavia\n\n\n1\n1934 Details\nItaly\nItaly\n2 - 1\nCzechoslovakia\nGermany\n3 - 2\nAustria\n\n\n2\n1938 Details\nFrance\nItaly\n4 - 2\nHungary\nBrazil\n4 - 2\nSweden\n\n\n3\n1950 Details\nBrazil\nUruguay\n2 - 1\nBrazil\nSweden\n[note 2]\nSpain\n\n\n4\n1954 Details\nSwitzerland\nWest Germany\n3 - 2\nHungary\nAustria\n3 - 1\nUruguay\n\n\n\n\n\n\n\n\n%pip install pdftotext\n\nDefaulting to user installation because normal site-packages is not writeable\nCollecting pdftotext\n  Downloading pdftotext-3.0.0.tar.gz (113 kB)\n     ------------------------------------ 113.6/113.6 kB 264.9 kB/s eta 0:00:00\n  Installing build dependencies: started\n  Installing build dependencies: still running...\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nBuilding wheels for collected packages: pdftotext\n  Building wheel for pdftotext (pyproject.toml): started\n  Building wheel for pdftotext (pyproject.toml): finished with status 'error'\nFailed to build pdftotext\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n\n\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\n\n\nmovies = soup.select('td.titleColumn')\ncrew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\nratings = [b.attrs.get('data-value')\n        for b in soup.select('td.posterColumn span[name=ir]')]\n\n\n# create a empty list for storing\n# movie information\nlist = []\n\n# Iterating over movies to extract\n# each movie's details\nfor index in range(0, len(movies)):\n    \n    # Separating movie into: 'place',\n    # 'title', 'year'\n    movie_string = movies[index].get_text()\n    movie = (' '.join(movie_string.split()).replace('.', ''))\n    movie_title = movie[len(str(index))+1:-7]\n    year = re.search('\\((.*?)\\)', movie_string).group(1)\n    place = movie[:len(str(index))-(len(movie))]\n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index],\n            \"year\": year,\n            \"star_cast\": crew[index],\n            }\n    list.append(data)\n\n\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['star_cast'], movie['rating'])\n\n\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\n\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\n\n%pip install requests\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: requests in d:\\programdata\\anaconda3\\lib\\site-packages (2.28.1)\nRequirement already satisfied: charset-normalizer&lt;3,&gt;=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n%pip install beautifulsoup4\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: beautifulsoup4 in d:\\programdata\\anaconda3\\lib\\site-packages (4.11.1)\nRequirement already satisfied: soupsieve&gt;1.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport requests\n \n# 定义请求的 URL 和 headers\nurl = \"https://movie.douban.com/top250\"\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n\n\nfrom bs4 import BeautifulSoup\n\n\nimport csv\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n\n\nimport csv\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据"
  },
  {
    "objectID": "labs/Practice/practice--2xujin.html",
    "href": "labs/Practice/practice--2xujin.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\n\n\nimport matplotlib as mpl\n\n\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\n\n\nfrom pathlib import Path\n\n\nimport pingouin as pg\n\n\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\nfile_path = '游戏.xlsx'\ndf = pd.read_excel(file_path, header=1)\n\n\ndf.columns = df.columns.str.strip()\n\n\nfile_path = '游戏.xlsx'\ndf = pd.read_excel(file_path, header=0)\n\n\ndf.columns = ['Round_Label', 'Round_10', 'Round_9', 'Round_8', 'Round_7', 'Round_6', 'Round_5', 'Round_4', 'Round_3', 'Round_2', 'Round_1']\nround_data = df.iloc[1, 1:]\nround_numbers = list(range(1, 11))\n\n\navg_contribution_df = pd.DataFrame({\n    'Round': round_numbers,\n    'Average Contribution': round_data.values\n})\n\n\nplt.figure(figsize=(10, 6))\nplt.plot(avg_contribution_df['Round'], avg_contribution_df['Average Contribution'], marker='o', linestyle='-', color='b')\nplt.title('Average Contribution Over Rounds')\nplt.xlabel('Round')\nplt.ylabel('Average Contribution')\nplt.grid(True)\nplt.xticks(round_numbers)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\navg_contribution_description = f\"\"\"\nAverage contributions have varied across the 10 rounds of the game. Here are the key observations:\n- Round 1: {avg_contribution_df.loc[avg_contribution_df['Round'] == 1, 'Average Contribution'].values[0]}\n- Round 10: {avg_contribution_df.loc[avg_contribution_df['Round'] == 10, 'Average Contribution'].values[0]}\n- Highest Average Contribution: {avg_contribution_df['Average Contribution'].max()} (Round {avg_contribution_df['Average Contribution'].idxmax() + 1})\n- Lowest Average Contribution: {avg_contribution_df['Average Contribution'].min()} (Round {avg_contribution_df['Average Contribution'].idxmin() + 1})\n\"\"\"\nprint(avg_contribution_description)\nplt.show()\n\n\nAverage contributions have varied across the 10 rounds of the game. Here are the key observations:\n- Round 1: 53.4\n- Round 10: 50\n- Highest Average Contribution: 58.4 (Round 9)\n- Lowest Average Contribution: 44.3 (Round 6)\n\n\n\n\n# Create a dictionary with the data in\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()\n\n\n\n\n\n\n\n\nCopenhagen\nDniprop\nMinsk\n\n\n\n\n0\n14.1\n11.0\n12.8\n\n\n1\n14.1\n12.6\n12.3\n\n\n2\n13.7\n12.1\n12.6\n\n\n3\n12.9\n11.2\n12.3\n\n\n4\n12.3\n11.3\n11.8\n\n\n\n\n\n\n\n\n# Plot the data\nfig, ax = plt.subplots()\ndf.plot(ax=ax)\nax.set_title(\"Average contributions to the public goods game: Without punishment\")\nax.set_ylabel(\"Average contribution\")\nax.set_xlabel(\"Round\");\n\n\n\n\n\n\n\n\n\nimport pandas as pd\n\n\nfile_path = \"doing-economics-datafile-working-in-excel-project-2.xlsx\"\n\n\nwithout_punishment = pd.read_excel(file_path, sheet_name=0, skiprows=1, nrows=10, usecols=\"B:Q\")\nwithout_punishment['Mean Contribution (Without Punishment)'] = without_punishment.mean(axis=1)\n\n\nwith_punishment = pd.read_excel(file_path, sheet_name=0, skiprows=28, nrows=10, usecols=\"B:Q\")\nwith_punishment['Mean Contribution (With Punishment)'] = with_punishment.mean(axis=1)\n\n\nprint(\"Mean Contributions Without Punishment:\")\nprint(without_punishment[['Mean Contribution (Without Punishment)']])\n\nprint(\"\\nMean Contributions With Punishment:\")\nprint(with_punishment[['Mean Contribution (With Punishment)']])\n\nMean Contributions Without Punishment:\n   Mean Contribution (Without Punishment)\n0                               10.578313\n1                               10.628398\n2                               10.407079\n3                                9.813033\n4                                9.305433\n5                                8.454844\n6                                7.837568\n7                                7.376388\n8                                6.392985\n9                                4.383769\n\nMean Contributions With Punishment:\nEmpty DataFrame\nColumns: [Mean Contribution (With Punishment)]\nIndex: []\n\n\n\npip install pandas matplotlib openpyxl\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (2.2.3)\nRequirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\lib\\site-packages (3.7.0)\nRequirement already satisfied: openpyxl in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (3.1.5)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.2)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\nRequirement already satisfied: numpy&gt;=1.22.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: fonttools&gt;=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: pillow&gt;=6.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\nRequirement already satisfied: cycler&gt;=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\nRequirement already satisfied: packaging&gt;=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\nRequirement already satisfied: et-xmlfile in d:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\nRequirement already satisfied: six&gt;=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfile_path = 'doing-economics-datafile-working-in-excel-project-2.xlsx'\ndf = pd.read_excel(file_path, sheet_name=None)\n\n\nwithout_punishment = pd.DataFrame()\nwith_punishment = pd.DataFrame()\n\n\nfor sheet_name, data in df.items():\n    if 'without punishment' in sheet_name.lower():\n        data = data.iloc[2:]\n\n\nfor sheet_name, data in df.items():\n    if 'without punishment' in sheet_name.lower():\n        data = data.iloc[2:]\n        mean_contributions = data.iloc[:, 1:].mean(axis=1)  \n        mean_contributions['Period'] = range(1, len(mean_contributions) + 1)\n        mean_contributions.set_index('Period', inplace=True)\n        mean_contributions.rename(columns={0: 'Mean Contribution'}, inplace=True)\n        if without_punishment.empty:\n            without_punishment = mean_contributions.copy()\n        else:\n            without_punishment = pd.concat([without_punishment, mean_contributions], ignore_index=True)\n            \n    elif 'with punishment' in sheet_name.lower():\n        data = data.iloc[2:]\n        mean_contributions = data.iloc[:, 1:].mean(axis=1)\n        mean_contributions['Period'] = range(1, len(mean_contributions) + 1)\n        mean_contributions.set_index('Period', inplace=True)\n        mean_contributions.rename(columns={0: 'Mean Contribution'}, inplace=True)\n        \n        if with_punishment.empty:\n            with_punishment = mean_contributions.copy()\n        else:\n            with_punishment = pd.concat([with_punishment, mean_contributions], ignore_index=True)\n\n\nimport pandas as pd\n\ndata_np = pd.read_excel(\n    'C:/Users/llll/Desktop/xujin homework/practice/doing-economics-datafile-working-in-excel-project-2.xlsx',\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\n\n\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\n\n\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\n\n\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\n\ntest_df=\n   City A  City B\n0    14.1    11.0\n1    14.1    99.0\n2    13.7    12.1\n\ntest_copy=\n   City A  City B\n0    14.1    11.0\n1    14.1    12.6\n2    13.7    12.1\n\n\n\n\ndata_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 10 entries, 1 to 10\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   Copenhagen       10 non-null     object\n 1   Dnipropetrovs’k  10 non-null     object\n 2   Minsk            10 non-null     object\n 3   St. Gallen       10 non-null     object\n 4   Muscat           10 non-null     object\n 5   Samara           10 non-null     object\n 6   Zurich           10 non-null     object\n 7   Boston           10 non-null     object\n 8   Bonn             10 non-null     object\n 9   Chengdu          10 non-null     object\n 10  Seoul            10 non-null     object\n 11  Riyadh           10 non-null     object\n 12  Nottingham       10 non-null     object\n 13  Athens           10 non-null     object\n 14  Istanbul         10 non-null     object\n 15  Melbourne        10 non-null     object\ndtypes: object(16)\nmemory usage: 1.3+ KB\n\n\n\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")\n\n\n# 使用 pd.to_numeric 转换，将无法转换的值设置为 NaN\ndata_n = data_n.apply(pd.to_numeric, errors='coerce')\ndata_p = data_p.apply(pd.to_numeric, errors='coerce')\n\n# 检查数据类型\nprint(data_n.dtypes)\nprint(data_p.dtypes)\n\nCopenhagen         float64\nDnipropetrovs’k    float64\nMinsk              float64\nSt. Gallen         float64\nMuscat             float64\nSamara             float64\nZurich             float64\nBoston             float64\nBonn               float64\nChengdu            float64\nSeoul              float64\nRiyadh             float64\nNottingham         float64\nAthens             float64\nIstanbul           float64\nMelbourne          float64\ndtype: object\nCopenhagen         float64\nDnipropetrovs’k    float64\nMinsk              float64\nSt. Gallen         float64\nMuscat             float64\nSamara             float64\nZurich             float64\nBoston             float64\nBonn               float64\nChengdu            float64\nSeoul              float64\nRiyadh             float64\nNottingham         float64\nAthens             float64\nIstanbul           float64\nMelbourne          float64\ndtype: object\n\n\n\nimport numpy as np\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\n\n\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();\n\n\n\n\n\n\n\n\n\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);\n\n\n\n\n\n\n\n\n\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\n\n\n\n\n\n\n\n\nstd\nvar\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n1\n2.020724\n4.083325\n10.578313\n\n\n2\n2.238129\n5.009220\n10.628398\n\n\n3\n2.329569\n5.426891\n10.407079\n\n\n4\n2.068213\n4.277504\n9.813033\n\n\n5\n2.108329\n4.445049\n9.305433\n\n\n6\n2.240881\n5.021549\n8.454844\n\n\n7\n2.136614\n4.565117\n7.837568\n\n\n8\n2.349442\n5.519880\n7.376388\n\n\n9\n2.413845\n5.826645\n6.392985\n\n\n10\n2.187126\n4.783520\n4.383769\n\n\n\n\n\n\n\n\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\n\n\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n\nPeriod\n1     10.199675\n2     12.185065\n3     12.689935\n4     12.625000\n5     12.140375\n6     12.827541\n7     13.098931\n8     13.482621\n9     13.496754\n10    11.307360\ndtype: float64\n\n\n\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\n\n50\n\n\n\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\n\n\nsumm_n.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n6.14\n14.10\n7.96\n2.02\n10.58\n\n\n10\n7.38\n8.68\n1.30\n2.19\n4.38\n\n\n\n\n\n\n\n\nsumm_p.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n10.20\n16.02\n5.82\n3.21\n10.64\n\n\n10\n11.31\n17.51\n6.20\n3.90\n12.87\n\n\n\n\n\n\n\n\nimport pingouin as pg\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.063782\n30\ntwo-sided\n0.949567\n[-2.0, 1.87]\n0.02255\n0.337\n0.050437\n\n\n\n\n\n\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.149959\n15\ntwo-sided\n0.882795\n[-0.92, 0.8]\n0.02255\n0.258\n0.05082\n\n\n\n\n\n\n\n\n# 创建一个包含索引1到11的新索引\nnew_index = range(1, 12)\n# 重新索引DataFrame，包括不存在的索引10\nreindexed_summ_n = summ_n.reindex(new_index)\n# 现在您可以安全地访问索引10（尽管它的值将是NaN）\nprint(reindexed_summ_n.loc[10, :].round(2))\n\nrange    7.38\nmax      8.68\nmin      1.30\nstd      2.19\nmean     4.38\nName: 10, dtype: float64"
  },
  {
    "objectID": "labs/Labexercises/Scores.html",
    "href": "labs/Labexercises/Scores.html",
    "title": "Scores",
    "section": "",
    "text": "Introduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406"
  },
  {
    "objectID": "labs/Labexercises/Occupation.html",
    "href": "labs/Labexercises/Occupation.html",
    "title": "Ex3 - Getting and Knowing your Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64"
  },
  {
    "objectID": "labs/Labexercises/Euro12.html",
    "href": "labs/Labexercises/Euro12.html",
    "title": "Ex2 - Filtering and Sorting Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%"
  },
  {
    "objectID": "labs/Labexercises/Chipotle1.html",
    "href": "labs/Labexercises/Chipotle1.html",
    "title": "Ex2 - Getting and Knowing your Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\ndata = pd.read_csv(url, sep='\\t')\nprint(data.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(chipo.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 4. See the first 10 entries\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(chipo.head(10))\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n5         3         1                           Chicken Bowl   \n6         3         1                          Side of Chips   \n7         4         1                          Steak Burrito   \n8         4         1                       Steak Soft Tacos   \n9         5         1                          Steak Burrito   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n5  [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...    $10.98   \n6                                                NaN     $1.69   \n7  [Tomatillo Red Chili Salsa, [Fajita Vegetables...    $11.75   \n8  [Tomatillo Green Chili Salsa, [Pinto Beans, Ch...     $9.25   \n9  [Fresh Tomato Salsa, [Rice, Black Beans, Pinto...     $9.25   \n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_observations = chipo.shape[0]\nprint(f\"The number of observations in the dataset is: {num_observations}\")\n\n\n\nThe number of observations in the dataset is: 4622\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_columns = chipo.shape[1]\nprint(f\"The number of columns in the dataset is: {num_columns}\")\n\nThe number of columns in the dataset is: 5\n\n\n\n\nStep 7. Print the name of all the columns.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(\"Column names:\", chipo.columns.tolist())\n\nColumn names: ['order_id', 'quantity', 'item_name', 'choice_description', 'item_price']\n\n\n\n\nStep 8. How is the dataset indexed?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(\"Dataset Index:\", chipo.index)\n\nDataset Index: RangeIndex(start=0, stop=4622, step=1)\n\n\n\n\nStep 9. Which was the most-ordered item?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nmost_ordered_item = chipo.groupby('item_name')['quantity'].sum().idxmax()\nprint(f\"The most-ordered item is: {most_ordered_item}\")\n\nThe most-ordered item is: Chicken Bowl\n\n\n\n\nStep 10. For the most-ordered item, how many items were ordered?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nitem_order_counts = chipo.groupby('item_name')['quantity'].sum()\nmost_ordered_item = item_order_counts.idxmax()\ntotal_quantity = item_order_counts.max()\nprint(f\"The most-ordered item is: {most_ordered_item}\")\nprint(f\"Total quantity ordered: {total_quantity}\")\n\nThe most-ordered item is: Chicken Bowl\nTotal quantity ordered: 761\n\n\n\n\nStep 11. What was the most ordered item in the choice_description column?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchoice_description_counts = chipo.groupby('choice_description')['quantity'].sum()\n\nmost_ordered_choice_description = choice_description_counts.idxmax()\ntotal_quantity_choice_description = choice_description_counts.max()\n\nprint(f\"The most-ordered choice description is: {most_ordered_choice_description}\")\nprint(f\"Total quantity ordered: {total_quantity_choice_description}\")\n\nThe most-ordered choice description is: [Diet Coke]\nTotal quantity ordered: 159\n\n\n\n\nStep 12. How many items were orderd in total?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\ntotal_items_ordered = chipo['quantity'].sum()\n\nprint(f\"Total number of items ordered: {total_items_ordered}\")\n\nTotal number of items ordered: 4972\n\n\n\n\nStep 13. Turn the item price into a float\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].replace({'\\$': ''}, regex=True).astype(float)\n\nprint(chipo.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description  item_price  \n0                                                NaN        2.39  \n1                                       [Clementine]        3.39  \n2                                            [Apple]        3.39  \n3                                                NaN        2.39  \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...       16.98  \n\n\n\nStep 13.a. Check the item price type\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].replace({'\\$': ''}, regex=True).astype(float)\n\nprint(f\"The data type of 'item_price' is: {chipo['item_price'].dtype}\")\n\nThe data type of 'item_price' is: float64\n\n\n\n\nStep 13.b. Create a lambda function and change the type of item price\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\n\nprint(f\"The data type of 'item_price' is: {chipo['item_price'].dtype}\")\n\nThe data type of 'item_price' is: float64\n\n\n\n\nStep 13.c. Check the item price type\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\n\nprint(f\"The data type of 'item_price' is: {chipo['item_price'].dtype}\")\n\nThe data type of 'item_price' is: float64\n\n\n\n\n\nStep 14. How much was the revenue for the period in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\n\nchipo['revenue'] = chipo['item_price'] * chipo['quantity']\n\ntotal_revenue = chipo['revenue'].sum()\n\nprint(f\"Total revenue for the period: ${total_revenue:.2f}\")\n\nTotal revenue for the period: $39237.02\n\n\n\n\nStep 15. How many orders were made in the period?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_orders = chipo.shape[0]\nprint(f\"Total number of orders in the period: {num_orders}\")\n\nTotal number of orders in the period: 4622\n\n\n\n\nStep 16. What is the average revenue amount per order?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\nchipo['revenue'] = chipo['item_price'] * chipo['quantity']\ntotal_revenue = chipo['revenue'].sum()\nnum_orders = chipo.shape[0]\naverage_revenue_per_order = total_revenue / num_orders\nprint(f\"Average revenue per order: ${average_revenue_per_order:.2f}\")\n\n\n\nAverage revenue per order: $8.49\n\n\n\n\nStep 17. How many different items are sold?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_different_items = chipo['item_name'].nunique()\nprint(f\"Number of different items sold: {num_different_items}\")\n\nNumber of different items sold: 50"
  },
  {
    "objectID": "homework/xujin.3.html",
    "href": "homework/xujin.3.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv('all-ages.csv')\n\n\ndf\n\n\n\n\n\n\n\n\nMajor_code\nMajor\nMajor_category\nTotal\nEmployed\nEmployed_full_time_year_round\nUnemployed\nUnemployment_rate\nMedian\nP25th\nP75th\n\n\n\n\n0\n1100\nGENERAL AGRICULTURE\nAgriculture & Natural Resources\n128148\n90245\n74078\n2423\n0.026147\n50000\n34000\n80000.0\n\n\n1\n1101\nAGRICULTURE PRODUCTION AND MANAGEMENT\nAgriculture & Natural Resources\n95326\n76865\n64240\n2266\n0.028636\n54000\n36000\n80000.0\n\n\n2\n1102\nAGRICULTURAL ECONOMICS\nAgriculture & Natural Resources\n33955\n26321\n22810\n821\n0.030248\n63000\n40000\n98000.0\n\n\n3\n1103\nANIMAL SCIENCES\nAgriculture & Natural Resources\n103549\n81177\n64937\n3619\n0.042679\n46000\n30000\n72000.0\n\n\n4\n1104\nFOOD SCIENCE\nAgriculture & Natural Resources\n24280\n17281\n12722\n894\n0.049188\n62000\n38500\n90000.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n168\n6211\nHOSPITALITY MANAGEMENT\nBusiness\n200854\n163393\n122499\n8862\n0.051447\n49000\n33000\n70000.0\n\n\n169\n6212\nMANAGEMENT INFORMATION SYSTEMS AND STATISTICS\nBusiness\n156673\n134478\n118249\n6186\n0.043977\n72000\n50000\n100000.0\n\n\n170\n6299\nMISCELLANEOUS BUSINESS & MEDICAL ADMINISTRATION\nBusiness\n102753\n77471\n61603\n4308\n0.052679\n53000\n36000\n83000.0\n\n\n171\n6402\nHISTORY\nHumanities & Liberal Arts\n712509\n478416\n354163\n33725\n0.065851\n50000\n35000\n80000.0\n\n\n172\n6403\nUNITED STATES HISTORY\nHumanities & Liberal Arts\n17746\n11887\n8204\n943\n0.073500\n50000\n39000\n81000.0\n\n\n\n\n173 rows × 11 columns\n\n\n\n\n# 按照专业分组，并把失业率从低到高升序排列\nresult = df.groupby([\"Major\"]).sum().sort_values([\"Unemployment_rate\"])\nprint(result)\n\n                                            Major_code  \\\nMajor                                                    \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING            2411   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION        2301   \nPHARMACOLOGY                                      3607   \nMATERIALS SCIENCE                                 5008   \nMATHEMATICS AND COMPUTER SCIENCE                  4005   \n...                                                ...   \nLIBRARY SCIENCE                                   3501   \nSCHOOL STUDENT COUNSELING                         2303   \nMILITARY TECHNOLOGIES                             3801   \nCLINICAL PSYCHOLOGY                               5202   \nMISCELLANEOUS FINE ARTS                           6099   \n\n                                                                 Major_category  \\\nMajor                                                                             \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING                              Engineering   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION                            Education   \nPHARMACOLOGY                                             Biology & Life Science   \nMATERIALS SCIENCE                                                   Engineering   \nMATHEMATICS AND COMPUTER SCIENCE                        Computers & Mathematics   \n...                                                                         ...   \nLIBRARY SCIENCE                                                       Education   \nSCHOOL STUDENT COUNSELING                                             Education   \nMILITARY TECHNOLOGIES                       Industrial Arts & Consumer Services   \nCLINICAL PSYCHOLOGY                                    Psychology & Social Work   \nMISCELLANEOUS FINE ARTS                                                    Arts   \n\n                                            Total  Employed  \\\nMajor                                                         \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING       6264      4120   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION   4037      3113   \nPHARMACOLOGY                                 5015      3481   \nMATERIALS SCIENCE                            7208      5866   \nMATHEMATICS AND COMPUTER SCIENCE             7184      5874   \n...                                           ...       ...   \nLIBRARY SCIENCE                             16193      7091   \nSCHOOL STUDENT COUNSELING                    2396      1492   \nMILITARY TECHNOLOGIES                        4315      1650   \nCLINICAL PSYCHOLOGY                          7638      5128   \nMISCELLANEOUS FINE ARTS                      8511      6431   \n\n                                            Employed_full_time_year_round  \\\nMajor                                                                       \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING                               3350   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION                           2468   \nPHARMACOLOGY                                                         2579   \nMATERIALS SCIENCE                                                    4505   \nMATHEMATICS AND COMPUTER SCIENCE                                     5039   \n...                                                                   ...   \nLIBRARY SCIENCE                                                      4330   \nSCHOOL STUDENT COUNSELING                                            1093   \nMILITARY TECHNOLOGIES                                                1708   \nCLINICAL PSYCHOLOGY                                                  3297   \nMISCELLANEOUS FINE ARTS                                              3802   \n\n                                            Unemployed  Unemployment_rate  \\\nMajor                                                                       \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING               0           0.000000   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION           0           0.000000   \nPHARMACOLOGY                                        57           0.016111   \nMATERIALS SCIENCE                                  134           0.022333   \nMATHEMATICS AND COMPUTER SCIENCE                   150           0.024900   \n...                                                ...                ...   \nLIBRARY SCIENCE                                    743           0.094843   \nSCHOOL STUDENT COUNSELING                          169           0.101746   \nMILITARY TECHNOLOGIES                              187           0.101796   \nCLINICAL PSYCHOLOGY                                587           0.102712   \nMISCELLANEOUS FINE ARTS                           1190           0.156147   \n\n                                            Median  P25th     P75th  \nMajor                                                                \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING       85000  55000  125000.0  \nEDUCATIONAL ADMINISTRATION AND SUPERVISION   58000  44750   79000.0  \nPHARMACOLOGY                                 60000  35000  105000.0  \nMATERIALS SCIENCE                            75000  60000  100000.0  \nMATHEMATICS AND COMPUTER SCIENCE             92000  53000  136000.0  \n...                                            ...    ...       ...  \nLIBRARY SCIENCE                              40000  30000   55000.0  \nSCHOOL STUDENT COUNSELING                    41000  33200   50000.0  \nMILITARY TECHNOLOGIES                        64000  39750   90000.0  \nCLINICAL PSYCHOLOGY                          45000  26100   62000.0  \nMISCELLANEOUS FINE ARTS                      45000  30000   60000.0  \n\n[173 rows x 10 columns]\n\n\n\nimport pandas as pd\ndf = pd.read_csv('recent-grads.csv')\ndf\n\n\n\n\n\n\n\n\nRank\nMajor_code\nMajor\nTotal\nMen\nWomen\nMajor_category\nShareWomen\nSample_size\nEmployed\n...\nPart_time\nFull_time_year_round\nUnemployed\nUnemployment_rate\nMedian\nP25th\nP75th\nCollege_jobs\nNon_college_jobs\nLow_wage_jobs\n\n\n\n\n0\n1\n2419\nPETROLEUM ENGINEERING\n2339.0\n2057.0\n282.0\nEngineering\n0.120564\n36\n1976\n...\n270\n1207\n37\n0.018381\n110000\n95000\n125000\n1534\n364\n193\n\n\n1\n2\n2416\nMINING AND MINERAL ENGINEERING\n756.0\n679.0\n77.0\nEngineering\n0.101852\n7\n640\n...\n170\n388\n85\n0.117241\n75000\n55000\n90000\n350\n257\n50\n\n\n2\n3\n2415\nMETALLURGICAL ENGINEERING\n856.0\n725.0\n131.0\nEngineering\n0.153037\n3\n648\n...\n133\n340\n16\n0.024096\n73000\n50000\n105000\n456\n176\n0\n\n\n3\n4\n2417\nNAVAL ARCHITECTURE AND MARINE ENGINEERING\n1258.0\n1123.0\n135.0\nEngineering\n0.107313\n16\n758\n...\n150\n692\n40\n0.050125\n70000\n43000\n80000\n529\n102\n0\n\n\n4\n5\n2405\nCHEMICAL ENGINEERING\n32260.0\n21239.0\n11021.0\nEngineering\n0.341631\n289\n25694\n...\n5180\n16697\n1672\n0.061098\n65000\n50000\n75000\n18314\n4440\n972\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n168\n169\n3609\nZOOLOGY\n8409.0\n3050.0\n5359.0\nBiology & Life Science\n0.637293\n47\n6259\n...\n2190\n3602\n304\n0.046320\n26000\n20000\n39000\n2771\n2947\n743\n\n\n169\n170\n5201\nEDUCATIONAL PSYCHOLOGY\n2854.0\n522.0\n2332.0\nPsychology & Social Work\n0.817099\n7\n2125\n...\n572\n1211\n148\n0.065112\n25000\n24000\n34000\n1488\n615\n82\n\n\n170\n171\n5202\nCLINICAL PSYCHOLOGY\n2838.0\n568.0\n2270.0\nPsychology & Social Work\n0.799859\n13\n2101\n...\n648\n1293\n368\n0.149048\n25000\n25000\n40000\n986\n870\n622\n\n\n171\n172\n5203\nCOUNSELING PSYCHOLOGY\n4626.0\n931.0\n3695.0\nPsychology & Social Work\n0.798746\n21\n3777\n...\n965\n2738\n214\n0.053621\n23400\n19200\n26000\n2403\n1245\n308\n\n\n172\n173\n3501\nLIBRARY SCIENCE\n1098.0\n134.0\n964.0\nEducation\n0.877960\n2\n742\n...\n237\n410\n87\n0.104946\n22000\n20000\n22000\n288\n338\n192\n\n\n\n\n173 rows × 21 columns\n\n\n\n\n# 按照专业分组，将女生占比从高到低降序排列\nresult = df.groupby([\"Major\"]).sum().sort_values([\"ShareWomen\"],ascending=False)\nprint(result)\n\n                                               Rank  Major_code     Total  \\\nMajor                                                                       \nEARLY CHILDHOOD EDUCATION                       165        2307   37589.0   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   164        6102   38279.0   \nMEDICAL ASSISTING SERVICES                       52        6104   11123.0   \nELEMENTARY EDUCATION                            139        2304  170862.0   \nFAMILY AND CONSUMER SCIENCES                    151        2901   58001.0   \n...                                             ...         ...       ...   \nMINING AND MINERAL ENGINEERING                    2        2416     756.0   \nCONSTRUCTION SERVICES                            27        5601   18498.0   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES      67        2504    4790.0   \nMILITARY TECHNOLOGIES                            74        3801     124.0   \nFOOD SCIENCE                                     22        1104       0.0   \n\n                                                   Men     Women  \\\nMajor                                                              \nEARLY CHILDHOOD EDUCATION                       1167.0   36422.0   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   1225.0   37054.0   \nMEDICAL ASSISTING SERVICES                       803.0   10320.0   \nELEMENTARY EDUCATION                           13029.0  157833.0   \nFAMILY AND CONSUMER SCIENCES                    5166.0   52835.0   \n...                                                ...       ...   \nMINING AND MINERAL ENGINEERING                   679.0      77.0   \nCONSTRUCTION SERVICES                          16820.0    1678.0   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES     4419.0     371.0   \nMILITARY TECHNOLOGIES                            124.0       0.0   \nFOOD SCIENCE                                       0.0       0.0   \n\n                                                                    Major_category  \\\nMajor                                                                                \nEARLY CHILDHOOD EDUCATION                                                Education   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES                               Health   \nMEDICAL ASSISTING SERVICES                                                  Health   \nELEMENTARY EDUCATION                                                     Education   \nFAMILY AND CONSUMER SCIENCES                   Industrial Arts & Consumer Services   \n...                                                                            ...   \nMINING AND MINERAL ENGINEERING                                         Engineering   \nCONSTRUCTION SERVICES                          Industrial Arts & Consumer Services   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES                            Engineering   \nMILITARY TECHNOLOGIES                          Industrial Arts & Consumer Services   \nFOOD SCIENCE                                       Agriculture & Natural Resources   \n\n                                               ShareWomen  Sample_size  \\\nMajor                                                                    \nEARLY CHILDHOOD EDUCATION                        0.968954          342   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES    0.967998           95   \nMEDICAL ASSISTING SERVICES                       0.927807           67   \nELEMENTARY EDUCATION                             0.923745         1629   \nFAMILY AND CONSUMER SCIENCES                     0.910933          518   \n...                                                   ...          ...   \nMINING AND MINERAL ENGINEERING                   0.101852            7   \nCONSTRUCTION SERVICES                            0.090713          295   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES      0.077453           71   \nMILITARY TECHNOLOGIES                            0.000000            4   \nFOOD SCIENCE                                     0.000000           36   \n\n                                               Employed  Full_time  Part_time  \\\nMajor                                                                           \nEARLY CHILDHOOD EDUCATION                         32551      27569       7001   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES     29763      19975      13862   \nMEDICAL ASSISTING SERVICES                         9168       5643       4107   \nELEMENTARY EDUCATION                             149339     123177      37965   \nFAMILY AND CONSUMER SCIENCES                      46624      36747      15872   \n...                                                 ...        ...        ...   \nMINING AND MINERAL ENGINEERING                      640        556        170   \nCONSTRUCTION SERVICES                             16318      15690       1751   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES        4186       4175        247   \nMILITARY TECHNOLOGIES                                 0        111          0   \nFOOD SCIENCE                                       3149       2558       1121   \n\n                                               Full_time_year_round  \\\nMajor                                                                 \nEARLY CHILDHOOD EDUCATION                                     20748   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES                 14460   \nMEDICAL ASSISTING SERVICES                                     4290   \nELEMENTARY EDUCATION                                          86540   \nFAMILY AND CONSUMER SCIENCES                                  26906   \n...                                                             ...   \nMINING AND MINERAL ENGINEERING                                  388   \nCONSTRUCTION SERVICES                                         12313   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES                    3607   \nMILITARY TECHNOLOGIES                                           111   \nFOOD SCIENCE                                                   1735   \n\n                                               Unemployed  Unemployment_rate  \\\nMajor                                                                          \nEARLY CHILDHOOD EDUCATION                            1360           0.040105   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES        1487           0.047584   \nMEDICAL ASSISTING SERVICES                            407           0.042507   \nELEMENTARY EDUCATION                                 7297           0.046586   \nFAMILY AND CONSUMER SCIENCES                         3355           0.067128   \n...                                                   ...                ...   \nMINING AND MINERAL ENGINEERING                         85           0.117241   \nCONSTRUCTION SERVICES                                1042           0.060023   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES           250           0.056357   \nMILITARY TECHNOLOGIES                                   0           0.000000   \nFOOD SCIENCE                                          338           0.096931   \n\n                                               Median  P25th  P75th  \\\nMajor                                                                 \nEARLY CHILDHOOD EDUCATION                       28000  21000  35000   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   28000  20000  40000   \nMEDICAL ASSISTING SERVICES                      42000  30000  65000   \nELEMENTARY EDUCATION                            32000  23400  38000   \nFAMILY AND CONSUMER SCIENCES                    30000  22900  40000   \n...                                               ...    ...    ...   \nMINING AND MINERAL ENGINEERING                  75000  55000  90000   \nCONSTRUCTION SERVICES                           50000  36000  60000   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES     40000  27000  52000   \nMILITARY TECHNOLOGIES                           40000  40000  40000   \nFOOD SCIENCE                                    53000  32000  70000   \n\n                                               College_jobs  Non_college_jobs  \\\nMajor                                                                           \nEARLY CHILDHOOD EDUCATION                             23515              7705   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES         19957              9404   \nMEDICAL ASSISTING SERVICES                             2091              6948   \nELEMENTARY EDUCATION                                 108085             36972   \nFAMILY AND CONSUMER SCIENCES                          20985             20133   \n...                                                     ...               ...   \nMINING AND MINERAL ENGINEERING                          350               257   \nCONSTRUCTION SERVICES                                  3275              5351   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES            1861              2121   \nMILITARY TECHNOLOGIES                                     0                 0   \nFOOD SCIENCE                                           1183              1274   \n\n                                               Low_wage_jobs  \nMajor                                                         \nEARLY CHILDHOOD EDUCATION                               2868  \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES           5125  \nMEDICAL ASSISTING SERVICES                              1270  \nELEMENTARY EDUCATION                                   11502  \nFAMILY AND CONSUMER SCIENCES                            5248  \n...                                                      ...  \nMINING AND MINERAL ENGINEERING                            50  \nCONSTRUCTION SERVICES                                    703  \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES              406  \nMILITARY TECHNOLOGIES                                      0  \nFOOD SCIENCE                                             485  \n\n[173 rows x 20 columns]\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\na=df['Median'].groupby(df['Major_category']).sum()\na.plot.bar()\nplt.show()"
  },
  {
    "objectID": "homework/xujin.1.out.html",
    "href": "homework/xujin.1.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndata = pd.read_csv('seattle_pet.1.csv')\nnum_pets = data. shape [0]\nprint(f\" {num_pets}\")\n\n 66042\n\n\n\nnum_variables = data.shape [1]\nprint(f\" {num_variables}\")\n\n 7\n\n\n\nname_counts = data['animal_s_name']. value_counts()\ntop_three_names = name_counts. head (3)\nprint (top_three_names)\n\nanimal_s_name\nLucy       566\nBella      451\nCharlie    447\nName: count, dtype: int64"
  },
  {
    "objectID": "homework/hw-majors.embed.html",
    "href": "homework/hw-majors.embed.html",
    "title": "HW - What should I major in?",
    "section": "",
    "text": "The first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "homework/hw-majors.embed.html#packages",
    "href": "homework/hw-majors.embed.html#packages",
    "title": "HW - What should I major in?",
    "section": "Packages",
    "text": "Packages\nUse pandas for data warnagling and processing,letsplot and matplotlib for visualization."
  },
  {
    "objectID": "homework/hw-majors.embed.html#data",
    "href": "homework/hw-majors.embed.html#data",
    "title": "HW - What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found on Kaggle.\nLet’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "homework/hw-majors.embed.html#which-major-has-the-lowest-unemployment-rate",
    "href": "homework/hw-majors.embed.html#which-major-has-the-lowest-unemployment-rate",
    "title": "HW - What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all you need to use pandas sorting and grouping functions."
  },
  {
    "objectID": "homework/hw-majors.embed.html#which-major-has-the-highest-percentage-of-women",
    "href": "homework/hw-majors.embed.html#which-major-has-the-highest-percentage-of-women",
    "title": "HW - What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors."
  },
  {
    "objectID": "homework/hw-majors.embed.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "homework/hw-majors.embed.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "HW - What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories. Create a hishogram. Consider the binwidth we chose for our histogram. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you’ll need to decide what this means) median income?\nWhich major category is the least popular in this sample?"
  },
  {
    "objectID": "homework/hw-majors.embed.html#all-stem-fields-arent-the-same",
    "href": "homework/hw-majors.embed.html#all-stem-fields-arent-the-same",
    "title": "HW - What should I major in?",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a list called stem_categories that lists the major categories that are considered STEM fields.\nThen, use this to create a new variable in our dataframe indicating whether a major is STEM or not.\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’ median earnings.\n\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top."
  },
  {
    "objectID": "homework/hw-majors.embed.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "homework/hw-majors.embed.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "HW - What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "homework/hw-majors.embed.html#further-exploration",
    "href": "homework/hw-majors.embed.html#further-exploration",
    "title": "HW - What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s)."
  },
  {
    "objectID": "homework/hw-majors.html",
    "href": "homework/hw-majors.html",
    "title": "HW - What should I major in?",
    "section": "",
    "text": "The first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "homework/hw-majors.html#packages",
    "href": "homework/hw-majors.html#packages",
    "title": "HW - What should I major in?",
    "section": "Packages",
    "text": "Packages\nUse pandas for data warnagling and processing,letsplot and matplotlib for visualization."
  },
  {
    "objectID": "homework/hw-majors.html#data",
    "href": "homework/hw-majors.html#data",
    "title": "HW - What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found on Kaggle.\nLet’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "homework/hw-majors.html#which-major-has-the-lowest-unemployment-rate",
    "href": "homework/hw-majors.html#which-major-has-the-lowest-unemployment-rate",
    "title": "HW - What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all you need to use pandas sorting and grouping functions."
  },
  {
    "objectID": "homework/hw-majors.html#which-major-has-the-highest-percentage-of-women",
    "href": "homework/hw-majors.html#which-major-has-the-highest-percentage-of-women",
    "title": "HW - What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors."
  },
  {
    "objectID": "homework/hw-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "homework/hw-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "HW - What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories. Create a hishogram. Consider the binwidth we chose for our histogram. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you’ll need to decide what this means) median income?\nWhich major category is the least popular in this sample?"
  },
  {
    "objectID": "homework/hw-majors.html#all-stem-fields-arent-the-same",
    "href": "homework/hw-majors.html#all-stem-fields-arent-the-same",
    "title": "HW - What should I major in?",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a list called stem_categories that lists the major categories that are considered STEM fields.\nThen, use this to create a new variable in our dataframe indicating whether a major is STEM or not.\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’ median earnings.\n\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top."
  },
  {
    "objectID": "homework/hw-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "homework/hw-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "HW - What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "homework/hw-majors.html#further-exploration",
    "href": "homework/hw-majors.html#further-exploration",
    "title": "HW - What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s)."
  },
  {
    "objectID": "homework/xujin.2.1.html",
    "href": "homework/xujin.2.1.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndata = pd.read_csv('nobel.2.1.csv')\nprint(data.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 935 entries, 0 to 934\nData columns (total 26 columns):\n #   Column                 Non-Null Count  Dtype \n---  ------                 --------------  ----- \n 0   id                     935 non-null    int64 \n 1   firstname              935 non-null    object\n 2   surname                906 non-null    object\n 3   year                   935 non-null    int64 \n 4   category               935 non-null    object\n 5   affiliation            685 non-null    object\n 6   city                   680 non-null    object\n 7   country                681 non-null    object\n 8   born_date              902 non-null    object\n 9   died_date              627 non-null    object\n 10  gender                 935 non-null    object\n 11  born_city              907 non-null    object\n 12  born_country           907 non-null    object\n 13  born_country_code      907 non-null    object\n 14  died_city              608 non-null    object\n 15  died_country           614 non-null    object\n 16  died_country_code      614 non-null    object\n 17  overall_motivation     17 non-null     object\n 18  share                  935 non-null    int64 \n 19  motivation             935 non-null    object\n 20  born_country_original  907 non-null    object\n 21  born_city_original     907 non-null    object\n 22  died_country_original  614 non-null    object\n 23  died_city_original     608 non-null    object\n 24  city_original          680 non-null    object\n 25  country_original       681 non-null    object\ndtypes: int64(3), object(23)\nmemory usage: 190.0+ KB\nNone\n\n\n\nprint(data.columns)\n\nIndex(['id', 'firstname', 'surname', 'year', 'category', 'affiliation', 'city',\n       'country', 'born_date', 'died_date', 'gender', 'born_city',\n       'born_country', 'born_country_code', 'died_city', 'died_country',\n       'died_country_code', 'overall_motivation', 'share', 'motivation',\n       'born_country_original', 'born_city_original', 'died_country_original',\n       'died_city_original', 'city_original', 'country_original'],\n      dtype='object')\n\n\n\nnobel_living = data[\n        (data['country'].notna ()) & \n    (data['gender'] !=  'org') & \n    (data['died_date'].isna())\n]\nprint(nobel_living.shape)\n\n(228, 26)\n\n\n\nlocation_counts = nobel_living['country']. value_counts ()\nmost_common_location = location_counts.idxmax()\nprint(f\": {most_common_location}\")\n\n: USA"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Xu Jin’s website and data analysis portfolio",
    "section": "",
    "text": "Hello, and thanks for visiting!\nWelcome to my website and data analysis portfolio.\nHere, I’ll feature my projects for the Fall 2024 Informational technologies in Business class.\nPlease use the Menu Bar above to look around."
  },
  {
    "objectID": "labs/Labexercises/Chipotle2.html",
    "href": "labs/Labexercises/Chipotle2.html",
    "title": "Ex1 - Filtering and Sorting Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nchipotle = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv', sep='\\t')\n\nprint(chipotle.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 3. Assign it to a variable called chipo.\n\n\nchipo = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv', sep='\\t')\n\n\nprint(chipo.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 4. How many products cost more than $10.00?\n\n\nchipo['item_price'] = chipo['item_price'].replace({'\\$': ''}, regex=True).astype(float)\n\nchipo_cleaned = chipo.drop_duplicates(subset=['item_name', 'quantity'])\n\nchipo_single_item = chipo_cleaned[chipo_cleaned['quantity'] == 1]\n\nexpensive_products = chipo_single_item[chipo_single_item['item_price'] &gt; 10.00]\n\nnum_expensive_products = expensive_products['item_name'].nunique()\n\nprint(f\"The number of products that cost more than $10.00 is: {num_expensive_products}\")\n\nThe number of products that cost more than $10.00 is: 12\n\n\n\n\nStep 5. What is the price of each item?\n\nprint a data frame with only two columns item_name and item_price\n\n\nchipo_cleaned = chipo.drop_duplicates(subset=['item_name', 'quantity'])\n\nchipo_single_item = chipo_cleaned[chipo_cleaned['quantity'] == 1]\n\nchipo_price_df = chipo_single_item[['item_name', 'item_price']]\n\nchipo_price_df_sorted = chipo_price_df.sort_values(by='item_price', ascending=False)\n\nprint(chipo_price_df_sorted)\n\n                                  item_name  item_price\n606                        Steak Salad Bowl       11.89\n1229                    Barbacoa Salad Bowl       11.89\n1132                    Carnitas Salad Bowl       11.89\n7                             Steak Burrito       11.75\n168                   Barbacoa Crispy Tacos       11.75\n39                            Barbacoa Bowl       11.75\n738                       Veggie Soft Tacos       11.25\n186                       Veggie Salad Bowl       11.25\n62                              Veggie Bowl       11.25\n57                           Veggie Burrito       11.25\n250                           Chicken Salad       10.98\n5                              Chicken Bowl       10.98\n8                          Steak Soft Tacos        9.25\n554                   Carnitas Crispy Tacos        9.25\n237                     Carnitas Soft Tacos        9.25\n56                      Barbacoa Soft Tacos        9.25\n92                       Steak Crispy Tacos        9.25\n664                             Steak Salad        8.99\n54                               Steak Bowl        8.99\n3750                         Carnitas Salad        8.99\n21                         Barbacoa Burrito        8.99\n27                         Carnitas Burrito        8.99\n33                            Carnitas Bowl        8.99\n11                     Chicken Crispy Tacos        8.75\n12                       Chicken Soft Tacos        8.75\n44                       Chicken Salad Bowl        8.75\n1653                    Veggie Crispy Tacos        8.49\n16                          Chicken Burrito        8.49\n1694                           Veggie Salad        8.49\n1414                                  Salad        7.40\n510                                 Burrito        7.40\n520                            Crispy Tacos        7.40\n673                                    Bowl        7.40\n298                       6 Pack Soft Drink        6.49\n10                      Chips and Guacamole        4.45\n1                                      Izze        3.39\n2                          Nantucket Nectar        3.39\n674       Chips and Mild Fresh Tomato Salsa        3.00\n111     Chips and Tomatillo Red Chili Salsa        2.95\n233      Chips and Roasted Chili Corn Salsa        2.95\n38    Chips and Tomatillo Green Chili Salsa        2.95\n3     Chips and Tomatillo-Green Chili Salsa        2.39\n300     Chips and Tomatillo-Red Chili Salsa        2.39\n191      Chips and Roasted Chili-Corn Salsa        2.39\n0              Chips and Fresh Tomato Salsa        2.39\n40                                    Chips        2.15\n6                             Side of Chips        1.69\n263                       Canned Soft Drink        1.25\n28                              Canned Soda        1.09\n34                            Bottled Water        1.09\n\n\n\n\n\nStep 6. Sort by the name of the item\n\nsorted_chipotle = chipotle.sort_values(by='item_name')\n\nprint(sorted_chipotle[['order_id', 'quantity', 'item_name', 'choice_description', 'item_price']])\n\n      order_id  quantity          item_name  \\\n3389      1360         2  6 Pack Soft Drink   \n341        148         1  6 Pack Soft Drink   \n1849       749         1  6 Pack Soft Drink   \n1860       754         1  6 Pack Soft Drink   \n2713      1076         1  6 Pack Soft Drink   \n...        ...       ...                ...   \n2384       948         1  Veggie Soft Tacos   \n781        322         1  Veggie Soft Tacos   \n2851      1132         1  Veggie Soft Tacos   \n1699       688         1  Veggie Soft Tacos   \n1395       567         1  Veggie Soft Tacos   \n\n                                     choice_description item_price  \n3389                                        [Diet Coke]    $12.98   \n341                                         [Diet Coke]     $6.49   \n1849                                             [Coke]     $6.49   \n1860                                        [Diet Coke]     $6.49   \n2713                                             [Coke]     $6.49   \n...                                                 ...        ...  \n2384  [Roasted Chili Corn Salsa, [Fajita Vegetables,...     $8.75   \n781   [Fresh Tomato Salsa, [Black Beans, Cheese, Sou...     $8.75   \n2851  [Roasted Chili Corn Salsa (Medium), [Black Bea...     $8.49   \n1699  [Fresh Tomato Salsa, [Fajita Vegetables, Rice,...    $11.25   \n1395  [Fresh Tomato Salsa (Mild), [Pinto Beans, Rice...     $8.49   \n\n[4622 rows x 5 columns]"
  },
  {
    "objectID": "labs/Labexercises/lab2/ppt.html#第一页",
    "href": "labs/Labexercises/lab2/ppt.html#第一页",
    "title": "演示文稿",
    "section": "第一页",
    "text": "第一页\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs/Labexercises/lab2/ppt.html#第二页",
    "href": "labs/Labexercises/lab2/ppt.html#第二页",
    "title": "演示文稿",
    "section": "第二页",
    "text": "第二页\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs/Labexercises/lab2/ppt.html#总结",
    "href": "labs/Labexercises/lab2/ppt.html#总结",
    "title": "演示文稿",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "labs/Labexercises/Open-food-facts.html",
    "href": "labs/Labexercises/Open-food-facts.html",
    "title": "Exercise 1",
    "section": "",
    "text": "Step 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'"
  },
  {
    "objectID": "labs/Labexercises/Visualizing.html",
    "href": "labs/Labexercises/Visualizing.html",
    "title": "Visualizing Chipotle’s Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()"
  },
  {
    "objectID": "labs/Practice/practice-1xujin.html",
    "href": "labs/Practice/practice-1xujin.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\n\n\nimport matplotlib as mpl\n\n\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\n\n\nfrom pathlib import Path\n\n\nimport pingouin as pg\n\n\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n\n### You don't need to use these settings yourself\n### — they are just here to make the book look nicer!\n# Set the plot style for prettier charts:\n#plt.style.use(\n#    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n#)\n\n\n#Python Walkthrough 1.1\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n\npip install pandas\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (2.2.3)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.2)\nRequirement already satisfied: numpy&gt;=1.22.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n# Python Walkthrough 1.1\nimport pandas as pd  # 导入 Pandas 库\n\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n# 现在您可以使用 df 进行后续的数据处理和分析\n\n\ndf.head()\n\n\n\n\n\n\n\n\nYear\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\n\n\n0\n1880\n-0.39\n-0.54\n-0.24\n-0.31\n-0.05\n-0.18\n-0.23\n-0.27\n-0.26\n-0.31\n-0.46\n-0.43\n-0.31\nNaN\nNaN\n-0.20\n-0.23\n-0.34\n\n\n1\n1881\n-0.31\n-0.26\n-0.07\n-0.03\n0.03\n-0.34\n0.08\n-0.06\n-0.29\n-0.45\n-0.38\n-0.24\n-0.19\n-0.21\n-0.33\n-0.02\n-0.11\n-0.37\n\n\n2\n1882\n0.25\n0.20\n0.01\n-0.31\n-0.24\n-0.29\n-0.28\n-0.17\n-0.26\n-0.53\n-0.34\n-0.69\n-0.22\n-0.18\n0.07\n-0.18\n-0.25\n-0.38\n\n\n3\n1883\n-0.58\n-0.66\n-0.15\n-0.30\n-0.26\n-0.11\n-0.06\n-0.23\n-0.34\n-0.16\n-0.45\n-0.15\n-0.29\n-0.33\n-0.64\n-0.24\n-0.13\n-0.32\n\n\n4\n1884\n-0.17\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.51\n-0.45\n-0.45\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145 entries, 0 to 144\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Year    145 non-null    int64  \n 1   Jan     145 non-null    float64\n 2   Feb     145 non-null    float64\n 3   Mar     145 non-null    float64\n 4   Apr     145 non-null    float64\n 5   May     145 non-null    float64\n 6   Jun     145 non-null    float64\n 7   Jul     145 non-null    float64\n 8   Aug     145 non-null    float64\n 9   Sep     145 non-null    float64\n 10  Oct     145 non-null    float64\n 11  Nov     144 non-null    float64\n 12  Dec     144 non-null    float64\n 13  J-D     144 non-null    float64\n 14  D-N     143 non-null    float64\n 15  DJF     144 non-null    float64\n 16  MAM     145 non-null    float64\n 17  JJA     145 non-null    float64\n 18  SON     144 non-null    float64\ndtypes: float64(18), int64(1)\nmemory usage: 21.6 KB\n\n\n\n#Python Walkthrough 1.2\n\ndf = df.set_index(\"Year\")\ndf.head()\ndf.tail()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020\n1.59\n1.70\n1.67\n1.40\n1.27\n1.14\n1.10\n1.12\n1.19\n1.21\n1.59\n1.19\n1.35\n1.36\n1.56\n1.44\n1.12\n1.33\n\n\n2021\n1.25\n0.96\n1.21\n1.13\n1.05\n1.21\n1.07\n1.03\n1.05\n1.30\n1.29\n1.17\n1.14\n1.14\n1.13\n1.13\n1.10\n1.21\n\n\n2022\n1.25\n1.17\n1.41\n1.09\n1.02\n1.13\n1.06\n1.17\n1.15\n1.31\n1.10\n1.06\n1.16\n1.17\n1.19\n1.17\n1.12\n1.19\n\n\n2023\n1.30\n1.30\n1.64\n1.02\n1.13\n1.19\n1.45\n1.57\n1.67\n1.88\n1.98\n1.85\n1.50\n1.43\n1.22\n1.26\n1.40\n1.84\n\n\n2024\n1.68\n1.93\n1.78\n1.80\n1.45\n1.54\n1.42\n1.42\n1.58\n1.72\nNaN\nNaN\nNaN\nNaN\n1.82\n1.67\n1.46\nNaN\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\ndf[\"Jan\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\npip install matplotlib\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\lib\\site-packages (3.7.0)\nRequirement already satisfied: numpy&gt;=1.20 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\nRequirement already satisfied: packaging&gt;=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: cycler&gt;=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: fonttools&gt;=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: contourpy&gt;=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\nRequirement already satisfied: six&gt;=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n# 导入 Matplotlib 的 pyplot 模块\nimport matplotlib.pyplot as plt\n\n# 创建图形和轴对象\nfig, ax = plt.subplots()\n\n# 假设 df 是已经定义好的 DataFrame，并且包含名为 \"Jan\" 的列\n# 注意：这里假设的代码没有显示 df 的定义和加载，您需要确保这部分已经正确完成\ndf[\"Jan\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\n\n# 显示图形\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\")\n\nText(0, 0.5, 'Annual temperature anomalies')\n\n\n\n\n\n\n\n\n\n\n#Python Walkthrough 1.3\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\")\n\nText(0, 0.5, 'Annual temperature anomalies')\n\n\n\n\n\n\n\n\n\n\n#Python Walkthrough 1.4\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n\n\ndf[\"Period\"].tail(20)\n\nYear\n2005    1981—2010\n2006    1981—2010\n2007    1981—2010\n2008    1981—2010\n2009    1981—2010\n2010    1981—2010\n2011          NaN\n2012          NaN\n2013          NaN\n2014          NaN\n2015          NaN\n2016          NaN\n2017          NaN\n2018          NaN\n2019          NaN\n2020          NaN\n2021          NaN\n2022          NaN\n2023          NaN\n2024          NaN\nName: Period, dtype: category\nCategories (3, object): ['1921—1950' &lt; '1951—1980' &lt; '1981—2010']\n\n\n\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\n\nYear     \n1880  Jun   -0.18\n      Jul   -0.23\n      Aug   -0.27\n1881  Jun   -0.34\n      Jul    0.08\ndtype: float64\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n#Python Walkthrough 1.5\n# Create a variable that has years 1951 to 1980, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at this data:\ntemp_all_months\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1951\nJan\n-0.36\n\n\n1\n1951\nFeb\n-0.51\n\n\n2\n1951\nMar\n-0.18\n\n\n3\n1951\nApr\n0.06\n\n\n4\n1951\nMay\n0.17\n\n\n...\n...\n...\n...\n\n\n355\n1980\nAug\n0.10\n\n\n356\n1980\nSep\n0.10\n\n\n357\n1980\nOct\n0.12\n\n\n358\n1980\nNov\n0.21\n\n\n359\n1980\nDec\n0.09\n\n\n\n\n360 rows × 3 columns\n\n\n\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is 17.099999999999998\nThe hot threshold of 70.0% is 25.9\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# 假设的 DataFrame，其中包含温度数据\ndata = {\n    \"values\": [10, 12, 15, 18, 20, 22, 25, 28, 30, 32]  # 示例温度数据\n}\ntemp_all_months = pd.DataFrame(data)\n\n# 定义分位数\nquantiles = [0.3, 0.7]\n\n# 计算给定分位数的值\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\n# 打印结果\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is 17.099999999999998\nThe hot threshold of 70.0% is 25.9\n\n\n\n#Python Walkthrough 1.6\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1981\nJan\n0.80\n\n\n1\n1981\nFeb\n0.62\n\n\n2\n1981\nMar\n0.68\n\n\n3\n1981\nApr\n0.39\n\n\n4\n1981\nMay\n0.18\n\n\n\n\n\n\n\n\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\n\nThe proportion under 17.099999999999998 is 100.00%\n\n\n\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\nThe proportion over 25.9 is 0.00%\n\n\n\n#Python Walkthrough 1.7\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"season\", 0: \"values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\n\n\n\n\n\n\n\n\nYear\nseason\nvalues\nPeriod\n\n\n\n\n443\n1991\nDJF\n0.51\n1981—2010\n\n\n444\n1991\nMAM\n0.45\n1981—2010\n\n\n445\n1991\nJJA\n0.42\n1981—2010\n\n\n446\n1991\nSON\n0.32\n1981—2010\n\n\n447\n1992\nDJF\n0.44\n1981—2010\n\n\n448\n1992\nMAM\n0.30\n1981—2010\n\n\n449\n1992\nJJA\n-0.04\n1981—2010\n\n\n450\n1992\nSON\n-0.15\n1981—2010\n\n\n451\n1993\nDJF\n0.37\n1981—2010\n\n\n452\n1993\nMAM\n0.31\n1981—2010\n\n\n\n\n\n\n\n\ngrp_mean_var = temp_all_months.groupby([\"season\", \"Period\"])[\"values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\nseason\nPeriod\n\n\n\n\n\n\nDJF\n1921—1950\n-0.026207\n0.057303\n\n\n1951—1980\n-0.002333\n0.050494\n\n\n1981—2010\n0.524333\n0.079646\n\n\nJJA\n1921—1950\n-0.052414\n0.021290\n\n\n1951—1980\n-0.000333\n0.014631\n\n\n1981—2010\n0.400333\n0.067727\n\n\nMAM\n1921—1950\n-0.041724\n0.031236\n\n\n1951—1980\n0.000333\n0.025245\n\n\n1981—2010\n0.510333\n0.076238\n\n\nSON\n1921—1950\n0.083103\n0.027751\n\n\n1951—1980\n-0.001000\n0.026258\n\n\n1981—2010\n0.429333\n0.111731\n\n\n\n\n\n\n\n\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"values\", color=\"season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n            \n            \n              \n                \n                  \n                    1951—1980 average\n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1880\n              \n            \n          \n          \n            \n            \n            \n              \n                1900\n              \n            \n          \n          \n            \n            \n            \n              \n                1920\n              \n            \n          \n          \n            \n            \n            \n              \n                1940\n              \n            \n          \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2020\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -1.0\n              \n            \n          \n          \n            \n              \n                -0.5\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.5\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n          \n            \n              \n                1.5\n              \n            \n          \n        \n      \n    \n    \n      \n        Average annual temperature anomaly in \n      \n      \n         in the northern hemisphere (1880—2024)\n      \n    \n    \n      \n        Annual temperature anomalies\n      \n    \n    \n      \n        Year\n      \n    \n    \n      \n      \n      \n        \n          \n            season\n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                MAM\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                JJA\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                SON\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                DJF\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\n#Python Walkthrough 1.8\ndf_co2 = pd.read_csv(\"C:\\Users\\llll\\Desktop\\xujin homework\\practice\\1_CO2-data.csv\")\ndf_co2.head()\n\n\n  Cell In[51], line 2\n    df_co2 = pd.read_csv(\"C:\\Users\\llll\\Desktop\\xujin homework\\practice\\1_CO2-data.csv\")\n                                                                                       ^\nSyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n\n\n\n\n\ndf_co2 = pd.read_csv(\"C:/Users/llll/Desktop/xujin homework/practice/1_CO2-data.csv\")\n\n\ndf_co2.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n0\n1958\n3\n315.71\n315.71\n314.62\n\n\n1\n1958\n4\n317.45\n317.45\n315.29\n\n\n2\n1958\n5\n317.50\n317.50\n314.71\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n4\n1958\n7\n315.86\n315.86\n314.98\n\n\n\n\n\n\n\n\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n15\n1959\n6\n318.15\n318.15\n315.92\n\n\n27\n1960\n6\n319.59\n319.59\n317.36\n\n\n39\n1961\n6\n319.77\n319.77\n317.48\n\n\n51\n1962\n6\n320.55\n320.55\n318.27\n\n\n\n\n\n\n\n\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n\n\n\n\n\n\n\n\nYear\nJun\nTrend\n\n\n\n\n0\n1958\n0.05\n314.85\n\n\n1\n1959\n0.14\n315.92\n\n\n2\n1960\n0.18\n317.36\n\n\n3\n1961\n0.18\n317.48\n\n\n4\n1962\n-0.13\n318.27\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.0\n              \n            \n          \n          \n            \n            \n            \n              \n                0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.4\n              \n            \n          \n          \n            \n            \n            \n              \n                0.6\n              \n            \n          \n          \n            \n            \n            \n              \n                0.8\n              \n            \n          \n          \n            \n            \n            \n              \n                1.0\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                320\n              \n            \n          \n          \n            \n              \n                340\n              \n            \n          \n          \n            \n              \n                360\n              \n            \n          \n          \n            \n              \n                380\n              \n            \n          \n          \n            \n              \n                400\n              \n            \n          \n        \n      \n    \n    \n      \n        Scatterplot of temperature anomalies vs carbon dioxide emissions\n      \n    \n    \n      \n        Carbon dioxide levels (trend, mole fraction)\n      \n    \n    \n      \n        Temperature anomaly (degrees Celsius)\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n\n\n\n\n\n\n\n\nJun\nTrend\n\n\n\n\nJun\n1.00000\n0.91495\n\n\nTrend\n0.91495\n1.00000\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.2\n              \n            \n          \n          \n            \n              \n                0.4\n              \n            \n          \n          \n            \n              \n                0.6\n              \n            \n          \n          \n            \n              \n                0.8\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n        \n      \n    \n    \n      \n        June temperature anomalies\n      \n    \n    \n      \n        Jun\n      \n    \n    \n      \n        Year\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n\n\n  \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  -0.2\n                \n              \n            \n            \n              \n                \n                  0.0\n                \n              \n            \n            \n              \n                \n                  0.2\n                \n              \n            \n            \n              \n                \n                  0.4\n                \n              \n            \n            \n              \n                \n                  0.6\n                \n              \n            \n            \n              \n                \n                  0.8\n                \n              \n            \n            \n              \n                \n                  1.0\n                \n              \n            \n          \n        \n      \n      \n        \n          June temperature anomalies\n        \n      \n      \n        \n          Jun\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  320\n                \n              \n            \n            \n              \n                \n                  340\n                \n              \n            \n            \n              \n                \n                  360\n                \n              \n            \n            \n              \n                \n                  380\n                \n              \n            \n            \n              \n                \n                  400\n                \n              \n            \n          \n        \n      \n      \n        \n          Carbon dioxide emissions\n        \n      \n      \n        \n          Trend\n        \n      \n      \n        \n          Year"
  },
  {
    "objectID": "labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets-1.html",
    "href": "labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets-1.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0"
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "Chipotle1",
    "section": "",
    "text": "Chipotle1\n\n\nEx2 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\ndata = pd.read_csv(url, sep='\\t')\nprint(data.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(chipo.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 4. See the first 10 entries\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(chipo.head(10))\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n5         3         1                           Chicken Bowl   \n6         3         1                          Side of Chips   \n7         4         1                          Steak Burrito   \n8         4         1                       Steak Soft Tacos   \n9         5         1                          Steak Burrito   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n5  [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...    $10.98   \n6                                                NaN     $1.69   \n7  [Tomatillo Red Chili Salsa, [Fajita Vegetables...    $11.75   \n8  [Tomatillo Green Chili Salsa, [Pinto Beans, Ch...     $9.25   \n9  [Fresh Tomato Salsa, [Rice, Black Beans, Pinto...     $9.25   \n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_observations = chipo.shape[0]\nprint(f\"The number of observations in the dataset is: {num_observations}\")\n\n\n\nThe number of observations in the dataset is: 4622\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_columns = chipo.shape[1]\nprint(f\"The number of columns in the dataset is: {num_columns}\")\n\nThe number of columns in the dataset is: 5\n\n\n\n\nStep 7. Print the name of all the columns.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(\"Column names:\", chipo.columns.tolist())\n\nColumn names: ['order_id', 'quantity', 'item_name', 'choice_description', 'item_price']\n\n\n\n\nStep 8. How is the dataset indexed?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(\"Dataset Index:\", chipo.index)\n\nDataset Index: RangeIndex(start=0, stop=4622, step=1)\n\n\n\n\nStep 9. Which was the most-ordered item?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nmost_ordered_item = chipo.groupby('item_name')['quantity'].sum().idxmax()\nprint(f\"The most-ordered item is: {most_ordered_item}\")\n\nThe most-ordered item is: Chicken Bowl\n\n\n\n\nStep 10. For the most-ordered item, how many items were ordered?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nitem_order_counts = chipo.groupby('item_name')['quantity'].sum()\nmost_ordered_item = item_order_counts.idxmax()\ntotal_quantity = item_order_counts.max()\nprint(f\"The most-ordered item is: {most_ordered_item}\")\nprint(f\"Total quantity ordered: {total_quantity}\")\n\nThe most-ordered item is: Chicken Bowl\nTotal quantity ordered: 761\n\n\n\n\nStep 11. What was the most ordered item in the choice_description column?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchoice_description_counts = chipo.groupby('choice_description')['quantity'].sum()\n\nmost_ordered_choice_description = choice_description_counts.idxmax()\ntotal_quantity_choice_description = choice_description_counts.max()\n\nprint(f\"The most-ordered choice description is: {most_ordered_choice_description}\")\nprint(f\"Total quantity ordered: {total_quantity_choice_description}\")\n\nThe most-ordered choice description is: [Diet Coke]\nTotal quantity ordered: 159\n\n\n\n\nStep 12. How many items were orderd in total?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\ntotal_items_ordered = chipo['quantity'].sum()\n\nprint(f\"Total number of items ordered: {total_items_ordered}\")\n\nTotal number of items ordered: 4972\n\n\n\n\nStep 13. Turn the item price into a float\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].replace({'\\\n\n\n\n\n# Euro12\n\n\n:::{.quarto-embed-nb-cell notebook=\"D:\\code\\jiedan\\12-28\\3-1-12.28-4183159359444112607\\labs\\Labexercises\\Euro12.ipynb\" notebook-title=\"Ex2 - Filtering and Sorting Data\" notebook-cellId=\"cell-0\"}\n\n# Ex2 - Filtering and Sorting Data\n\nThis time we are going to pull data directly from the internet.\n\n### Step 1. Import the necessary libraries\n\n::: {#cell-2 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%\n\n\n\nSource: Ex2 - Getting and Knowing your Data\n\nOccupation\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64\n\n\n\nSource: Ex3 - Getting and Knowing your Data\n\nOpen-food-facts\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\nSource: Exercise 1\n\nScores\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406\n\n\n\nSource: Scores\n\nVisualizing-Chipotle’s-Data\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()\n\n\n\n\n\n\n\n\n\nSource: Visualizing Chipotle's Data\n: ’’}, regex=True).astype(float)\nprint(chipo.head())\n\n::: {.cell-output .cell-output-stdout}\norder_id quantity item_name\n0 1 1 Chips and Fresh Tomato Salsa\n1 1 1 Izze\n2 1 1 Nantucket Nectar\n3 1 1 Chips and Tomatillo-Green Chili Salsa\n4 2 2 Chicken Bowl\n                              choice_description  item_price  \n0 NaN 2.39\n1 [Clementine] 3.39\n2 [Apple] 3.39\n3 NaN 2.39\n4 [Tomatillo-Red Chili Salsa (Hot), [Black Beans… 16.98\n:::\n:::\n\n\n#### Step 13.a. Check the item price type\n\n::: {#cell-28 .cell execution_count=14}\n``` {.python .cell-code}\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].replace({'\\\n\n\n\n\n# Euro12\n\n\n:::{.quarto-embed-nb-cell notebook=\"D:\\code\\jiedan\\12-28\\3-1-12.28-4183159359444112607\\labs\\Labexercises\\Euro12.ipynb\" notebook-title=\"Ex2 - Filtering and Sorting Data\" notebook-cellId=\"cell-0\"}\n\n# Ex2 - Filtering and Sorting Data\n\nThis time we are going to pull data directly from the internet.\n\n### Step 1. Import the necessary libraries\n\n::: {#cell-2 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n:::\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%\n\n\n:::\n\n\nOccupation\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64\n\n\n\n\n\nOpen-food-facts\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\n\n\nScores\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406\n\n\n\n\n\nVisualizing-Chipotle’s-Data\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n: ’’}, regex=True).astype(float)\nprint(f”The data type of ‘item_price’ is: {chipo[‘item_price’].dtype}“)\n\n::: {.cell-output .cell-output-stdout}\nThe data type of ‘item_price’ is: float64\n:::\n:::\n\n\n#### Step 13.b. Create a lambda function and change the type of item price\n\n::: {#cell-30 .cell execution_count=15}\n``` {.python .cell-code}\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('\n\n\n\n\n# Euro12\n\n\n:::{.quarto-embed-nb-cell notebook=\"D:\\code\\jiedan\\12-28\\3-1-12.28-4183159359444112607\\labs\\Labexercises\\Euro12.ipynb\" notebook-title=\"Ex2 - Filtering and Sorting Data\" notebook-cellId=\"cell-0\"}\n\n# Ex2 - Filtering and Sorting Data\n\nThis time we are going to pull data directly from the internet.\n\n### Step 1. Import the necessary libraries\n\n::: {#cell-2 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n:::\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%\n\n\n:::\n\n\nOccupation\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64\n\n\n\n\n\nOpen-food-facts\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\n\n\nScores\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406\n\n\n\n\n\nVisualizing-Chipotle’s-Data\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n, ’’)))\nprint(f”The data type of ‘item_price’ is: {chipo[‘item_price’].dtype}“)\n\n::: {.cell-output .cell-output-stdout}\nThe data type of ‘item_price’ is: float64\n:::\n:::\n\n\n#### Step 13.c. Check the item price type\n\n::: {#cell-32 .cell execution_count=16}\n``` {.python .cell-code}\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('\n\n\n\n\n# Euro12\n\n\n:::{.quarto-embed-nb-cell notebook=\"D:\\code\\jiedan\\12-28\\3-1-12.28-4183159359444112607\\labs\\Labexercises\\Euro12.ipynb\" notebook-title=\"Ex2 - Filtering and Sorting Data\" notebook-cellId=\"cell-0\"}\n\n# Ex2 - Filtering and Sorting Data\n\nThis time we are going to pull data directly from the internet.\n\n### Step 1. Import the necessary libraries\n\n::: {#cell-2 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n:::\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%\n\n\n:::\n\n\nOccupation\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64\n\n\n\n\n\nOpen-food-facts\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\n\n\nScores\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406\n\n\n\n\n\nVisualizing-Chipotle’s-Data\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n, ’’)))\nprint(f”The data type of ‘item_price’ is: {chipo[‘item_price’].dtype}“)\n\n::: {.cell-output .cell-output-stdout}\nThe data type of ‘item_price’ is: float64\n:::\n:::\n\n\n### Step 14. How much was the revenue for the period in the dataset?\n\n::: {#cell-34 .cell execution_count=17}\n``` {.python .cell-code}\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('\n\n\n\n\n# Euro12\n\n\n:::{.quarto-embed-nb-cell notebook=\"D:\\code\\jiedan\\12-28\\3-1-12.28-4183159359444112607\\labs\\Labexercises\\Euro12.ipynb\" notebook-title=\"Ex2 - Filtering and Sorting Data\" notebook-cellId=\"cell-0\"}\n\n# Ex2 - Filtering and Sorting Data\n\nThis time we are going to pull data directly from the internet.\n\n### Step 1. Import the necessary libraries\n\n::: {#cell-2 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n:::\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%\n\n\n:::\n\n\nOccupation\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64\n\n\n\n\n\nOpen-food-facts\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\n\n\nScores\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406\n\n\n\n\n\nVisualizing-Chipotle’s-Data\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n, ’’)))\nchipo[‘revenue’] = chipo[‘item_price’] * chipo[‘quantity’]\ntotal_revenue = chipo[‘revenue’].sum()\nprint(f”Total revenue for the period: ${total_revenue:.2f}“)\n\n::: {.cell-output .cell-output-stdout}\nTotal revenue for the period: $39237.02\n:::\n:::\n\n\n### Step 15. How many orders were made in the period?\n\n::: {#cell-36 .cell execution_count=18}\n``` {.python .cell-code}\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_orders = chipo.shape[0]\nprint(f\"Total number of orders in the period: {num_orders}\")\n\n\nTotal number of orders in the period: 4622\n\n:::\n\nStep 16. What is the average revenue amount per order?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('\n\n\n\n\n# Euro12\n\n\n:::{.quarto-embed-nb-cell notebook=\"D:\\code\\jiedan\\12-28\\3-1-12.28-4183159359444112607\\labs\\Labexercises\\Euro12.ipynb\" notebook-title=\"Ex2 - Filtering and Sorting Data\" notebook-cellId=\"cell-0\"}\n\n# Ex2 - Filtering and Sorting Data\n\nThis time we are going to pull data directly from the internet.\n\n### Step 1. Import the necessary libraries\n\n::: {#cell-2 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%\n\n\n:::\n\n\nOccupation\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64\n\n\n\n\n\nOpen-food-facts\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\n\n\nScores\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406\n\n\n\n\n\nVisualizing-Chipotle’s-Data\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n, ’’))) chipo[‘revenue’] = chipo[‘item_price’] * chipo[‘quantity’] total_revenue = chipo[‘revenue’].sum() num_orders = chipo.shape[0] average_revenue_per_order = total_revenue / num_orders print(f”Average revenue per order: ${average_revenue_per_order:.2f}“)\n\n::: {.cell-output .cell-output-stdout}\nAverage revenue per order: $8.49\n:::\n:::\n\n\n### Step 17. How many different items are sold?\n\n::: {#cell-40 .cell execution_count=20}\n``` {.python .cell-code}\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_different_items = chipo['item_name'].nunique()\nprint(f\"Number of different items sold: {num_different_items}\")\n\n\nNumber of different items sold: 50\n\n:::\n:::\n\nEuro12\n\n\nEx2 - Filtering and Sorting Data\nThis time we are going to pull data directly from the internet.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%\n\n\n\nSource: Ex2 - Filtering and Sorting Data\n\nOccupation\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64\n\n\n\n\n\nOpen-food-facts\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000000003087/farine-de-ble-noir-ferme-t-y-r-nao\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000000004530/banana-chips-sweetened-whole\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000000004559/peanuts-torn-glasser\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000000016087/organic-salted-nut-mix-grizzlies\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000000016094/organic-polenta-bob-s-red-mill\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape)\nprint(food.shape[1])\n\nfood.info()\n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood['-glucose_100g'].dtype\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\npd.set_option('display.max_colwidth', 300)\n\n\nfood[['code','url']]\n\n\n\n\n\n\n\n\ncode\nurl\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\n\n\n...\n...\n...\n\n\n356022\n99567453\nhttp://world-en.openfoodfacts.org/product/9956...\n\n\n356023\n9970229501521\nhttp://world-en.openfoodfacts.org/product/9970...\n\n\n356024\n9977471758307\nhttp://world-en.openfoodfacts.org/product/9977...\n\n\n356025\n9980282863788\nhttp://world-en.openfoodfacts.org/product/9980...\n\n\n356026\n999990026839\nhttp://world-en.openfoodfacts.org/product/9999...\n\n\n\n\n356027 rows × 2 columns\n\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.at[18, 'product_name']\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\n\n\nScores\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406\n\n\n\n\n\nVisualizing-Chipotle’s-Data\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\nx = chipo.item_name\n\nletter_counts = Counter(x)\n\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\ndf = df[0].sort_values(ascending = True)[45:50]\n\ndf.plot(kind='bar')\n\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\norders = chipo.groupby('order_id').sum()\n\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n\n\n\n\n\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\nWhich menu items have the highest unit prices and how do the number of orders for these menu items vary?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep = '\\t')\n\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price]\n\nmost_expensive_items = chipo.groupby('item_name').item_price.mean().sort_values(ascending=False).head(10)\n\ntop_items = chipo[chipo['item_name'].isin(most_expensive_items.index)]\nitem_order_counts = top_items.groupby('item_name')['quantity'].sum()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nitem_order_counts.plot(kind='bar', ax=ax, color='skyblue')\n\nax.set_xlabel('Menu Item')\nax.set_ylabel('Total Quantity Ordered')\nax.set_title('Top 10 Most Expensive Menu Items and Their Order Quantities')\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()"
  },
  {
    "objectID": "labs.html#第一页",
    "href": "labs.html#第一页",
    "title": "Chipotle1",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs.html#第二页",
    "href": "labs.html#第二页",
    "title": "Chipotle1",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs.html#总结",
    "href": "labs.html#总结",
    "title": "Chipotle1",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "labs.html#第一页-1",
    "href": "labs.html#第一页-1",
    "title": "Chipotle1",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs.html#第二页-1",
    "href": "labs.html#第二页-1",
    "title": "Chipotle1",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs.html#总结-1",
    "href": "labs.html#总结-1",
    "title": "Chipotle1",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "labs.html#第一页-2",
    "href": "labs.html#第一页-2",
    "title": "Chipotle1",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs.html#第二页-2",
    "href": "labs.html#第二页-2",
    "title": "Chipotle1",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs.html#总结-2",
    "href": "labs.html#总结-2",
    "title": "Chipotle1",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "labs.html#第一页-3",
    "href": "labs.html#第一页-3",
    "title": "Chipotle1",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs.html#第二页-3",
    "href": "labs.html#第二页-3",
    "title": "Chipotle1",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs.html#总结-3",
    "href": "labs.html#总结-3",
    "title": "Chipotle1",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "labs.html#第一页-4",
    "href": "labs.html#第一页-4",
    "title": "Chipotle1",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs.html#第二页-4",
    "href": "labs.html#第二页-4",
    "title": "Chipotle1",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs.html#总结-4",
    "href": "labs.html#总结-4",
    "title": "Chipotle1",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "labs.html#第一页-5",
    "href": "labs.html#第一页-5",
    "title": "Chipotle1",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs.html#第二页-5",
    "href": "labs.html#第二页-5",
    "title": "Chipotle1",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs.html#总结-5",
    "href": "labs.html#总结-5",
    "title": "Chipotle1",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "labs.html#第一页-6",
    "href": "labs.html#第一页-6",
    "title": "Chipotle1",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs.html#第二页-6",
    "href": "labs.html#第二页-6",
    "title": "Chipotle1",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs.html#总结-6",
    "href": "labs.html#总结-6",
    "title": "Chipotle1",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Hi, I’m Xu Jin!",
    "section": "",
    "text": "My name is Xu Jin, I am 27 years old this year, and I am at the age of passion for my dream. Looking back on my education, I graduated from Jincheng College of Nanjing University of Aeronautics and Astronautics (NUAA), where I laid a solid foundation of knowledge."
  },
  {
    "objectID": "about.html#travel-exploration",
    "href": "about.html#travel-exploration",
    "title": "Hi, I’m Xu Jin!",
    "section": "Travel & Exploration",
    "text": "Travel & Exploration\nAfter work and study, I am obsessed with short videos. In the fragmented time, the fingertip slide, you can shuttle in the food production, travel exploration, science popularization and other forms of wonderful world, not only can relax the tense nerves, but also capture the creative inspiration, for my work and learning to inject a different kind of vitality."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Hi, I’m Xu Jin!",
    "section": "Education",
    "text": "Education\nAfter graduation, I devote myself to education and become a counselor in Jincheng College of Vocational Technology, and in the blink of an eye, I have had two years of valuable work time. In these two years, I witnessed the students from ignorant and shy to gradually confident and mature, their metamorphosis, is the medal of my work. Every heart-to-heart talk and class meeting is an opportunity for me to pass on my warmth and strength, and to help them cross the academic hurdles and solve the confusion in their lives, which makes me more and more firm in my love for this profession."
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "Hi, I’m Xu Jin!",
    "section": "Work Experience",
    "text": "Work Experience\nAt present, I am still studying at the Belarusian State University, majoring in education management. The journey of studying in a foreign country is like a feast of knowledge, where educational concepts from different cultures collide and mingle, broadening my horizons and allowing me to look at the nature of education in a higher dimension."
  },
  {
    "objectID": "about.html#looking-forward",
    "href": "about.html#looking-forward",
    "title": "Hi, I’m Xu Jin!",
    "section": "Looking Forward",
    "text": "Looking Forward\nI know that my past experience is like a jigsaw puzzle, which has shaped me into the person I am today. In the future, with this love and accumulation, I will be fearless of challenges, embrace opportunities, dig deep into the infinite possibilities of education, and endeavor to write more splendid poems on education in the book of life, and I look forward to sharing more wonderful stories of growth with all my fellow travelers!"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "HW - What should I major in?",
    "section": "",
    "text": "import pandas as pd\ndata = pd.read_csv('seattle_pet.1.csv')\nnum_pets = data. shape [0]\nprint(f\" {num_pets}\")\n\n 66042\n\n\n\nnum_variables = data.shape [1]\nprint(f\" {num_variables}\")\n\n 7\n\n\n\nname_counts = data['animal_s_name']. value_counts()\ntop_three_names = name_counts. head (3)\nprint (top_three_names)\n\nanimal_s_name\nLucy       566\nBella      451\nCharlie    447\nName: count, dtype: int64\n\n\nSource: xujin.1.ipynb"
  },
  {
    "objectID": "homework.html#packages",
    "href": "homework.html#packages",
    "title": "HW - What should I major in?",
    "section": "Packages",
    "text": "Packages\nUse pandas for data warnagling and processing,letsplot and matplotlib for visualization."
  },
  {
    "objectID": "homework.html#data",
    "href": "homework.html#data",
    "title": "HW - What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found on Kaggle.\nLet’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "homework.html#which-major-has-the-lowest-unemployment-rate",
    "href": "homework.html#which-major-has-the-lowest-unemployment-rate",
    "title": "HW - What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all you need to use pandas sorting and grouping functions."
  },
  {
    "objectID": "homework.html#which-major-has-the-highest-percentage-of-women",
    "href": "homework.html#which-major-has-the-highest-percentage-of-women",
    "title": "HW - What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors."
  },
  {
    "objectID": "homework.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "homework.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "HW - What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories. Create a hishogram. Consider the binwidth we chose for our histogram. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you’ll need to decide what this means) median income?\nWhich major category is the least popular in this sample?"
  },
  {
    "objectID": "homework.html#all-stem-fields-arent-the-same",
    "href": "homework.html#all-stem-fields-arent-the-same",
    "title": "HW - What should I major in?",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a list called stem_categories that lists the major categories that are considered STEM fields.\nThen, use this to create a new variable in our dataframe indicating whether a major is STEM or not.\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’ median earnings.\n\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top."
  },
  {
    "objectID": "homework.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "homework.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "HW - What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "homework.html#further-exploration",
    "href": "homework.html#further-exploration",
    "title": "HW - What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s)."
  },
  {
    "objectID": "labs/Labexercises/lab2/ppt.embed.html",
    "href": "labs/Labexercises/lab2/ppt.embed.html",
    "title": "演示文稿",
    "section": "",
    "text": "Xu Jin\n2024-12-31"
  },
  {
    "objectID": "labs/Labexercises/lab2/ppt.embed.html#第一页",
    "href": "labs/Labexercises/lab2/ppt.embed.html#第一页",
    "title": "演示文稿",
    "section": "第一页",
    "text": "第一页\n\n主要内容\n\n这是第一页\n简单的要点展示\n清晰明了"
  },
  {
    "objectID": "labs/Labexercises/lab2/ppt.embed.html#第二页",
    "href": "labs/Labexercises/lab2/ppt.embed.html#第二页",
    "title": "演示文稿",
    "section": "第二页",
    "text": "第二页\n\n重点内容\n\n第一个重点\n第二个重点\n第三个重点\n\n这是演讲者注释，只有演讲者能看到"
  },
  {
    "objectID": "labs/Labexercises/lab2/ppt.embed.html#总结",
    "href": "labs/Labexercises/lab2/ppt.embed.html#总结",
    "title": "演示文稿",
    "section": "总结",
    "text": "总结\n\n回顾要点\n未来展望\n感谢聆听"
  },
  {
    "objectID": "docs/labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets-1.out.html",
    "href": "docs/labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets-1.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0"
  },
  {
    "objectID": "docs/labs/Practice/practice-1xujin.out.html",
    "href": "docs/labs/Practice/practice-1xujin.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\n\n\nimport matplotlib as mpl\n\n\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\n\n\nfrom pathlib import Path\n\n\nimport pingouin as pg\n\n\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n\n### You don't need to use these settings yourself\n### — they are just here to make the book look nicer!\n# Set the plot style for prettier charts:\n#plt.style.use(\n#    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n#)\n\n\n#Python Walkthrough 1.1\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n\npip install pandas\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (2.2.3)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\llll\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.2)\nRequirement already satisfied: numpy&gt;=1.22.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n# Python Walkthrough 1.1\nimport pandas as pd  # 导入 Pandas 库\n\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n# 现在您可以使用 df 进行后续的数据处理和分析\n\n\ndf.head()"
  },
  {
    "objectID": "docs/labs/Labexercises/Visualizing.out.html",
    "href": "docs/labs/Labexercises/Visualizing.out.html",
    "title": "Visualizing Chipotle’s Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)"
  },
  {
    "objectID": "docs/labs/Labexercises/Open-food-facts.out.html",
    "href": "docs/labs/Labexercises/Open-food-facts.out.html",
    "title": "Exercise 1",
    "section": "",
    "text": "Step 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\n\n\nfood  = pd.read_csv('en.openfoodfacts.org.products.tsv.zip', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n5 rows × 163 columns"
  },
  {
    "objectID": "docs/labs/Labexercises/Euro12.out.html",
    "href": "docs/labs/Labexercises/Euro12.out.html",
    "title": "Ex2 - Filtering and Sorting Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv')\n\nprint(euro12)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Saves made  \\\n0              0              0                     0  ...          13   \n1              0              0                     0  ...           9   \n2              1              0                     0  ...          10   \n3              0              0                     0  ...          22   \n4              1              0                     0  ...           6   \n5              2              1                     0  ...          10   \n6              1              1                     1  ...          13   \n7              2              0                     0  ...          20   \n8              2              0                     0  ...          12   \n9              0              0                     0  ...           6   \n10             6              0                     0  ...          10   \n11             0              0                     0  ...          17   \n12             2              0                     0  ...          10   \n13             0              1                     0  ...          15   \n14             3              0                     0  ...           8   \n15             0              0                     0  ...          13   \n\n    Saves-to-shots ratio  Fouls Won Fouls Conceded  Offsides  Yellow Cards  \\\n0                  81.3%         41             62         2             9   \n1                  60.1%         53             73         8             7   \n2                  66.7%         25             38         8             4   \n3                  88.1%         43             45         6             5   \n4                  54.6%         36             51         5             6   \n5                  62.6%         63             49        12             4   \n6                  65.1%         67             48        12             9   \n7                  74.1%        101             89        16            16   \n8                  70.6%         35             30         3             5   \n9                  66.7%         48             56         3             7   \n10                 71.5%         73             90        10            12   \n11                 65.4%         43             51        11             6   \n12                 77.0%         34             43         4             6   \n13                 93.8%        102             83        19            11   \n14                 61.6%         35             51         7             7   \n15                 76.5%         48             31         4             5   \n\n    Red Cards  Subs on  Subs off  Players Used  \n0           0        9         9            16  \n1           0       11        11            19  \n2           0        7         7            15  \n3           0       11        11            16  \n4           0       11        11            19  \n5           0       15        15            17  \n6           1       12        12            20  \n7           0       18        18            19  \n8           0        7         7            15  \n9           1        7         7            17  \n10          0       14        14            16  \n11          1       10        10            17  \n12          0        7         7            16  \n13          0       17        17            18  \n14          0        9         9            18  \n15          0        9         9            18  \n\n[16 rows x 35 columns]\n\n\n\n\nStep 4. Select only the Goal column.\n\ngoals = euro12['Goals']\nprint(goals)\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\nnum_teams = euro12.shape[0]\nprint(f'Number of teams participated: {num_teams}')\n\nNumber of teams participated: 16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\nprint(discipline)\n\n                   Team  Yellow Cards  Red Cards\n0               Croatia             9          0\n1        Czech Republic             7          0\n2               Denmark             4          0\n3               England             5          0\n4                France             6          0\n5               Germany             4          0\n6                Greece             9          1\n7                 Italy            16          0\n8           Netherlands             5          0\n9                Poland             7          1\n10             Portugal            12          0\n11  Republic of Ireland             6          1\n12               Russia             6          0\n13                Spain            11          0\n14               Sweden             7          0\n15              Ukraine             5          0\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\nsorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[False, False])\nprint(sorted_discipline)\n\n                   Team  Yellow Cards  Red Cards\n6                Greece             9          1\n9                Poland             7          1\n11  Republic of Ireland             6          1\n7                 Italy            16          0\n10             Portugal            12          0\n13                Spain            11          0\n0               Croatia             9          0\n1        Czech Republic             7          0\n14               Sweden             7          0\n4                France             6          0\n12               Russia             6          0\n3               England             5          0\n8           Netherlands             5          0\n15              Ukraine             5          0\n2               Denmark             4          0\n5               Germany             4          0\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n# Calculate the mean Yellow Cards given per Team and round to 1 decimal place\nmean_yellow_cards = round(euro12['Yellow Cards'].mean(), 1)\n\n# Display the result\nprint(mean_yellow_cards)\n\n\n\n7.4\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\nteams_more_than_6_goals = euro12[euro12['Goals'] &gt; 6]\n\ngermany_spain = teams_more_than_6_goals[teams_more_than_6_goals['Team'].isin(['Germany', 'Spain'])]\n\nprint(germany_spain)\n\n\n       Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5   Germany     10               32                32             47.8%   \n13    Spain     12               42                33             55.9%   \n\n   % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5             15.6%                          80             2              1   \n13            16.0%                         100             0              1   \n\n    Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                      0  ...          10                 62.6%         63   \n13                     0  ...          15                 93.8%        102   \n\n   Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5              49        12             4          0       15        15   \n13             83        19            11          0       17        17   \n\n    Players Used  \n5             17  \n13            18  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 11. Select the teams that start with G\n\nteams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\nprint(teams_start_with_G)\n\n      Team  Goals  Shots on target  Shots off target Shooting Accuracy  \\\n5  Germany     10               32                32             47.8%   \n6   Greece      5                8                18             30.7%   \n\n  % Goals-to-shots  Total shots (inc. Blocked)  Hit Woodwork  Penalty goals  \\\n5            15.6%                          80             2              1   \n6            19.2%                          32             1              1   \n\n   Penalties not scored  ...  Saves made  Saves-to-shots ratio  Fouls Won  \\\n5                     0  ...          10                 62.6%         63   \n6                     1  ...          13                 65.1%         67   \n\n  Fouls Conceded  Offsides  Yellow Cards  Red Cards  Subs on  Subs off  \\\n5             49        12             4          0       15        15   \n6             48        12             9          1       12        12   \n\n   Players Used  \n5            17  \n6            20  \n\n[2 rows x 35 columns]\n\n\n\n\nStep 12. Select the first 7 columns\n\nfirst_7_columns = euro12.iloc[:, :7]\nprint(first_7_columns)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \n0              51.9%            16.0%                          32  \n1              41.9%            12.9%                          39  \n2              50.0%            20.0%                          27  \n3              50.0%            17.2%                          40  \n4              37.9%             6.5%                          65  \n5              47.8%            15.6%                          80  \n6              30.7%            19.2%                          32  \n7              43.0%             7.5%                         110  \n8              25.0%             4.1%                          60  \n9              39.4%             5.2%                          48  \n10             34.3%             9.3%                          82  \n11             36.8%             5.2%                          28  \n12             22.5%            12.5%                          59  \n13             55.9%            16.0%                         100  \n14             47.2%            13.8%                          39  \n15             21.2%             6.0%                          38  \n\n\n\n\nStep 13. Select all columns except the last 3.\n\ncolumns_excluding_last_3 = euro12.iloc[:, :-3]\nprint(columns_excluding_last_3)\n\n                   Team  Goals  Shots on target  Shots off target  \\\n0               Croatia      4               13                12   \n1        Czech Republic      4               13                18   \n2               Denmark      4               10                10   \n3               England      5               11                18   \n4                France      3               22                24   \n5               Germany     10               32                32   \n6                Greece      5                8                18   \n7                 Italy      6               34                45   \n8           Netherlands      2               12                36   \n9                Poland      2               15                23   \n10             Portugal      6               22                42   \n11  Republic of Ireland      1                7                12   \n12               Russia      5                9                31   \n13                Spain     12               42                33   \n14               Sweden      5               17                19   \n15              Ukraine      2                7                26   \n\n   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n0              51.9%            16.0%                          32   \n1              41.9%            12.9%                          39   \n2              50.0%            20.0%                          27   \n3              50.0%            17.2%                          40   \n4              37.9%             6.5%                          65   \n5              47.8%            15.6%                          80   \n6              30.7%            19.2%                          32   \n7              43.0%             7.5%                         110   \n8              25.0%             4.1%                          60   \n9              39.4%             5.2%                          48   \n10             34.3%             9.3%                          82   \n11             36.8%             5.2%                          28   \n12             22.5%            12.5%                          59   \n13             55.9%            16.0%                         100   \n14             47.2%            13.8%                          39   \n15             21.2%             6.0%                          38   \n\n    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n0              0              0                     0  ...             0   \n1              0              0                     0  ...             1   \n2              1              0                     0  ...             1   \n3              0              0                     0  ...             2   \n4              1              0                     0  ...             1   \n5              2              1                     0  ...             1   \n6              1              1                     1  ...             1   \n7              2              0                     0  ...             2   \n8              2              0                     0  ...             0   \n9              0              0                     0  ...             0   \n10             6              0                     0  ...             2   \n11             0              0                     0  ...             0   \n12             2              0                     0  ...             0   \n13             0              1                     0  ...             5   \n14             3              0                     0  ...             1   \n15             0              0                     0  ...             0   \n\n    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n0       10               3         13                 81.3%         41   \n1       10               6          9                 60.1%         53   \n2       10               5         10                 66.7%         25   \n3       29               3         22                 88.1%         43   \n4        7               5          6                 54.6%         36   \n5       11               6         10                 62.6%         63   \n6       23               7         13                 65.1%         67   \n7       18               7         20                 74.1%        101   \n8        9               5         12                 70.6%         35   \n9        8               3          6                 66.7%         48   \n10      11               4         10                 71.5%         73   \n11      23               9         17                 65.4%         43   \n12       8               3         10                 77.0%         34   \n13       8               1         15                 93.8%        102   \n14      12               5          8                 61.6%         35   \n15       4               4         13                 76.5%         48   \n\n    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n0               62         2             9          0  \n1               73         8             7          0  \n2               38         8             4          0  \n3               45         6             5          0  \n4               51         5             6          0  \n5               49        12             4          0  \n6               48        12             9          1  \n7               89        16            16          0  \n8               30         3             5          0  \n9               56         3             7          1  \n10              90        10            12          0  \n11              51        11             6          1  \n12              43         4             6          0  \n13              83        19            11          0  \n14              51         7             7          0  \n15              31         4             5          0  \n\n[16 rows x 32 columns]\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\nshooting_accuracy = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\nprint(shooting_accuracy)\n\n       Team Shooting Accuracy\n3   England             50.0%\n7     Italy             43.0%\n12   Russia             22.5%"
  },
  {
    "objectID": "docs/homework/xujin.lecture.5.out.html",
    "href": "docs/homework/xujin.lecture.5.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nurl ='https://raw.githubusercontent.com/tidyverse/datascience-box/refs/heads/main/course-materials/lab-instructions/lab-02/data/plastic-waste.csv'\ndf = pd.read_csv(url)\ndf\n\n\n240 rows × 10 columns"
  },
  {
    "objectID": "docs/homework/xujin.2.2.out.html",
    "href": "docs/homework/xujin.2.2.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nfrom skimpy import skim\ndf = pd. read_csv(\"shujuji2.2.csv\")\nskim (df)\n\n╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n│          Data Summary                Data Types                                                                 │\n│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n│ ┃ dataframe         ┃ Values ┃ ┃ Column Type ┃ Count ┃                                                          │\n│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n│ │ Number of rows    │ 891    │ │ int32       │ 5     │                                                          │\n│ │ Number of columns │ 12     │ │ string      │ 5     │                                                          │\n│ └───────────────────┴────────┘ │ float64     │ 2     │                                                          │\n│                                └─────────────┴───────┘                                                          │\n│                                                     number                                                      │\n│ ┏━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓  │\n│ ┃ column_name    ┃ NA   ┃ NA %    ┃ mean     ┃ sd       ┃ p0    ┃ p25    ┃ p50    ┃ p75    ┃ p100   ┃ hist   ┃  │\n│ ┡━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩  │\n│ │ PassengerId    │    0 │       0 │      446 │    257.4 │     1 │  223.5 │    446 │  668.5 │    891 │ ▇▇▇▇▇▇ │  │\n│ │ Survived       │    0 │       0 │   0.3838 │   0.4866 │     0 │      0 │      0 │      1 │      1 │ ▇    ▅ │  │\n│ │ Pclass         │    0 │       0 │    2.309 │   0.8361 │     1 │      2 │      3 │      3 │      3 │ ▃  ▃ ▇ │  │\n│ │ Age            │  177 │   19.87 │     29.7 │    14.53 │  0.42 │  20.12 │     28 │     38 │     80 │ ▂▇▇▃▁  │  │\n│ │ SibSp          │    0 │       0 │    0.523 │    1.103 │     0 │      0 │      0 │      1 │      8 │   ▇    │  │\n│ │ Parch          │    0 │       0 │   0.3816 │   0.8061 │     0 │      0 │      0 │      0 │      6 │  ▇▁▁   │  │\n│ │ Fare           │    0 │       0 │     32.2 │    49.69 │     0 │   7.91 │  14.45 │     31 │  512.3 │   ▇    │  │\n│ └────────────────┴──────┴─────────┴──────────┴──────────┴───────┴────────┴────────┴────────┴────────┴────────┘  │\n│                                                     string                                                      │\n│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n│ ┃ column_name              ┃ NA       ┃ NA %       ┃ words per row                ┃ total words              ┃  │\n│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n│ │ Name                     │        0 │          0 │                          4.1 │                     3626 │  │\n│ │ Sex                      │        0 │          0 │                            1 │                      891 │  │\n│ │ Ticket                   │        0 │          0 │                          1.3 │                     1130 │  │\n│ │ Cabin                    │      687 │       77.1 │                         0.27 │                      238 │  │\n│ │ Embarked                 │        2 │       0.22 │                            1 │                      889 │  │\n│ └──────────────────────────┴──────────┴────────────┴──────────────────────────────┴──────────────────────────┘  │\n╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n\n\n\n\nprint(df.head())\n\n   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n\n\n\nprint(df .describe())\n\n       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  \n\n\n\nprint(df.isnull().sum())\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\nprint(df.dtypes)\n\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\n\n\nimport matplotlib.pyplot as plt\nsurvival_counts = df[ 'Survived']. value_counts()\nsurvival_counts. plot(kind='bar')\nplt. title( 'Survival Counts')\nplt. xlabel ('Survived')\nplt. ylabel ('Count')\nplt.xticks(ticks=[0, 1], labels=['No', 'Yes'], rotation=0)\nplt.show\ngender_survival = df.groupby(['Sex', 'Survived']). size() .unstack()\ngender_survival.plot(kind='bar', stacked=True)\nplt. title( 'Survival by Gender')\nplt.xlabel ( 'Gender')\nplt. ylabel ('Count')\nplt.xticks(rotation=0)\nplt. show()"
  },
  {
    "objectID": "docs/homework/xujin.1.out.html",
    "href": "docs/homework/xujin.1.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndata = pd.read_csv('seattle_pet.1.csv')\nnum_pets = data. shape [0]\nprint(f\" {num_pets}\")\n\n 66042\n\n\n\nnum_variables = data.shape [1]\nprint(f\" {num_variables}\")\n\n 7\n\n\n\nname_counts = data['animal_s_name']. value_counts()\ntop_three_names = name_counts. head (3)\nprint (top_three_names)\n\nanimal_s_name\nLucy       566\nBella      451\nCharlie    447\nName: count, dtype: int64"
  },
  {
    "objectID": "docs/homework/xujin.2.1.out.html",
    "href": "docs/homework/xujin.2.1.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndata = pd.read_csv('nobel.2.1.csv')\nprint(data.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 935 entries, 0 to 934\nData columns (total 26 columns):\n #   Column                 Non-Null Count  Dtype \n---  ------                 --------------  ----- \n 0   id                     935 non-null    int64 \n 1   firstname              935 non-null    object\n 2   surname                906 non-null    object\n 3   year                   935 non-null    int64 \n 4   category               935 non-null    object\n 5   affiliation            685 non-null    object\n 6   city                   680 non-null    object\n 7   country                681 non-null    object\n 8   born_date              902 non-null    object\n 9   died_date              627 non-null    object\n 10  gender                 935 non-null    object\n 11  born_city              907 non-null    object\n 12  born_country           907 non-null    object\n 13  born_country_code      907 non-null    object\n 14  died_city              608 non-null    object\n 15  died_country           614 non-null    object\n 16  died_country_code      614 non-null    object\n 17  overall_motivation     17 non-null     object\n 18  share                  935 non-null    int64 \n 19  motivation             935 non-null    object\n 20  born_country_original  907 non-null    object\n 21  born_city_original     907 non-null    object\n 22  died_country_original  614 non-null    object\n 23  died_city_original     608 non-null    object\n 24  city_original          680 non-null    object\n 25  country_original       681 non-null    object\ndtypes: int64(3), object(23)\nmemory usage: 190.0+ KB\nNone\n\n\n\nprint(data.columns)\n\nIndex(['id', 'firstname', 'surname', 'year', 'category', 'affiliation', 'city',\n       'country', 'born_date', 'died_date', 'gender', 'born_city',\n       'born_country', 'born_country_code', 'died_city', 'died_country',\n       'died_country_code', 'overall_motivation', 'share', 'motivation',\n       'born_country_original', 'born_city_original', 'died_country_original',\n       'died_city_original', 'city_original', 'country_original'],\n      dtype='object')\n\n\n\nnobel_living = data[\n        (data['country'].notna ()) & \n    (data['gender'] !=  'org') & \n    (data['died_date'].isna())\n]\nprint(nobel_living.shape)\n\n(228, 26)\n\n\n\nlocation_counts = nobel_living['country']. value_counts ()\nmost_common_location = location_counts.idxmax()\nprint(f\": {most_common_location}\")\n\n: USA"
  },
  {
    "objectID": "docs/homework/xujin.3.out.html",
    "href": "docs/homework/xujin.3.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv('all-ages.csv')\n\n\ndf\n\n\n173 rows × 11 columns"
  },
  {
    "objectID": "docs/labs/Labexercises/Chipotle1.out.html",
    "href": "docs/labs/Labexercises/Chipotle1.out.html",
    "title": "Ex2 - Getting and Knowing your Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\ndata = pd.read_csv(url, sep='\\t')\nprint(data.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(chipo.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n\n\n\n\nStep 4. See the first 10 entries\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(chipo.head(10))\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n5         3         1                           Chicken Bowl   \n6         3         1                          Side of Chips   \n7         4         1                          Steak Burrito   \n8         4         1                       Steak Soft Tacos   \n9         5         1                          Steak Burrito   \n\n                                  choice_description item_price  \n0                                                NaN     $2.39   \n1                                       [Clementine]     $3.39   \n2                                            [Apple]     $3.39   \n3                                                NaN     $2.39   \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n5  [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...    $10.98   \n6                                                NaN     $1.69   \n7  [Tomatillo Red Chili Salsa, [Fajita Vegetables...    $11.75   \n8  [Tomatillo Green Chili Salsa, [Pinto Beans, Ch...     $9.25   \n9  [Fresh Tomato Salsa, [Rice, Black Beans, Pinto...     $9.25   \n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_observations = chipo.shape[0]\nprint(f\"The number of observations in the dataset is: {num_observations}\")\n\n\n\nThe number of observations in the dataset is: 4622\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_columns = chipo.shape[1]\nprint(f\"The number of columns in the dataset is: {num_columns}\")\n\nThe number of columns in the dataset is: 5\n\n\n\n\nStep 7. Print the name of all the columns.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(\"Column names:\", chipo.columns.tolist())\n\nColumn names: ['order_id', 'quantity', 'item_name', 'choice_description', 'item_price']\n\n\n\n\nStep 8. How is the dataset indexed?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nprint(\"Dataset Index:\", chipo.index)\n\nDataset Index: RangeIndex(start=0, stop=4622, step=1)\n\n\n\n\nStep 9. Which was the most-ordered item?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nmost_ordered_item = chipo.groupby('item_name')['quantity'].sum().idxmax()\nprint(f\"The most-ordered item is: {most_ordered_item}\")\n\nThe most-ordered item is: Chicken Bowl\n\n\n\n\nStep 10. For the most-ordered item, how many items were ordered?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nitem_order_counts = chipo.groupby('item_name')['quantity'].sum()\nmost_ordered_item = item_order_counts.idxmax()\ntotal_quantity = item_order_counts.max()\nprint(f\"The most-ordered item is: {most_ordered_item}\")\nprint(f\"Total quantity ordered: {total_quantity}\")\n\nThe most-ordered item is: Chicken Bowl\nTotal quantity ordered: 761\n\n\n\n\nStep 11. What was the most ordered item in the choice_description column?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchoice_description_counts = chipo.groupby('choice_description')['quantity'].sum()\n\nmost_ordered_choice_description = choice_description_counts.idxmax()\ntotal_quantity_choice_description = choice_description_counts.max()\n\nprint(f\"The most-ordered choice description is: {most_ordered_choice_description}\")\nprint(f\"Total quantity ordered: {total_quantity_choice_description}\")\n\nThe most-ordered choice description is: [Diet Coke]\nTotal quantity ordered: 159\n\n\n\n\nStep 12. How many items were orderd in total?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\ntotal_items_ordered = chipo['quantity'].sum()\n\nprint(f\"Total number of items ordered: {total_items_ordered}\")\n\nTotal number of items ordered: 4972\n\n\n\n\nStep 13. Turn the item price into a float\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].replace({'\\$': ''}, regex=True).astype(float)\n\nprint(chipo.head())\n\n   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n\n                                  choice_description  item_price  \n0                                                NaN        2.39  \n1                                       [Clementine]        3.39  \n2                                            [Apple]        3.39  \n3                                                NaN        2.39  \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...       16.98  \n\n\n\nStep 13.a. Check the item price type\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].replace({'\\$': ''}, regex=True).astype(float)\n\nprint(f\"The data type of 'item_price' is: {chipo['item_price'].dtype}\")\n\nThe data type of 'item_price' is: float64\n\n\n\n\nStep 13.b. Create a lambda function and change the type of item price\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\n\nprint(f\"The data type of 'item_price' is: {chipo['item_price'].dtype}\")\n\nThe data type of 'item_price' is: float64\n\n\n\n\nStep 13.c. Check the item price type\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\n\nprint(f\"The data type of 'item_price' is: {chipo['item_price'].dtype}\")\n\nThe data type of 'item_price' is: float64\n\n\n\n\n\nStep 14. How much was the revenue for the period in the dataset?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\n\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\n\nchipo['revenue'] = chipo['item_price'] * chipo['quantity']\n\ntotal_revenue = chipo['revenue'].sum()\n\nprint(f\"Total revenue for the period: ${total_revenue:.2f}\")\n\nTotal revenue for the period: $39237.02\n\n\n\n\nStep 15. How many orders were made in the period?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_orders = chipo.shape[0]\nprint(f\"Total number of orders in the period: {num_orders}\")\n\nTotal number of orders in the period: 4622\n\n\n\n\nStep 16. What is the average revenue amount per order?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nchipo['item_price'] = chipo['item_price'].apply(lambda x: float(x.replace('$', '')))\nchipo['revenue'] = chipo['item_price'] * chipo['quantity']\ntotal_revenue = chipo['revenue'].sum()\nnum_orders = chipo.shape[0]\naverage_revenue_per_order = total_revenue / num_orders\nprint(f\"Average revenue per order: ${average_revenue_per_order:.2f}\")\n\n\n\nAverage revenue per order: $8.49\n\n\n\n\nStep 17. How many different items are sold?\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\nchipo = pd.read_csv(url, sep='\\t')\nnum_different_items = chipo['item_name'].nunique()\nprint(f\"Number of different items sold: {num_different_items}\")\n\nNumber of different items sold: 50"
  },
  {
    "objectID": "docs/labs/Labexercises/Occupation.out.html",
    "href": "docs/labs/Labexercises/Occupation.out.html",
    "title": "Ex3 - Getting and Knowing your Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nuser_data = pd.read_csv(url, delimiter='|')\n\n\nprint(user_data.head())\n\n   user_id  age gender  occupation zip_code\n0        1   24      M  technician    85711\n1        2   53      F       other    94043\n2        3   23      M      writer    32067\n3        4   24      M  technician    43537\n4        5   33      F       other    15213\n\n\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n\n\nusers = pd.read_csv(url, delimiter='|', index_col='user_id')\n\n\nprint(users.head())\n\n         age gender  occupation zip_code\nuser_id                                 \n1         24      M  technician    85711\n2         53      F       other    94043\n3         23      M      writer    32067\n4         24      M  technician    43537\n5         33      F       other    15213\n\n\n\n\nStep 4. See the first 25 entries\n\n\nprint(users.head(25))\n\n         age gender     occupation zip_code\nuser_id                                    \n1         24      M     technician    85711\n2         53      F          other    94043\n3         23      M         writer    32067\n4         24      M     technician    43537\n5         33      F          other    15213\n6         42      M      executive    98101\n7         57      M  administrator    91344\n8         36      M  administrator    05201\n9         29      M        student    01002\n10        53      M         lawyer    90703\n11        39      F          other    30329\n12        28      F          other    06405\n13        47      M       educator    29206\n14        45      M      scientist    55106\n15        49      F       educator    97301\n16        21      M  entertainment    10309\n17        30      M     programmer    06355\n18        35      F          other    37212\n19        40      M      librarian    02138\n20        42      F      homemaker    95660\n21        26      M         writer    30068\n22        25      M         writer    40206\n23        30      F         artist    48197\n24        21      F         artist    94533\n25        39      M       engineer    55107\n\n\n\n\nStep 5. See the last 10 entries\n\n\nprint(users.tail(10))\n\n         age gender     occupation zip_code\nuser_id                                    \n934       61      M       engineer    22902\n935       42      M         doctor    66221\n936       24      M          other    32789\n937       48      M       educator    98072\n938       38      F     technician    55038\n939       26      F        student    33319\n940       32      M  administrator    02215\n941       20      M        student    97229\n942       48      F      librarian    78209\n943       22      M        student    77841\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\n# Get the number of observations (rows) in the dataset\nnum_observations = users.shape[0]\n\n# Print the number of observations\nprint(f\"Number of observations in the dataset: {num_observations}\")\n\nNumber of observations in the dataset: 943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\n\nnum_columns = users.shape[1]\n\n\nprint(f\"Number of columns in the dataset: {num_columns}\")\n\nNumber of columns in the dataset: 4\n\n\n\n\nStep 8. Print the name of all the columns.\n\n\nprint(users.columns)\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\n\nprint(users.index)\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\n\nprint(users.dtypes)\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\n\nprint(users['occupation'])\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nnum_occupations = users['occupation'].nunique()\n\nprint(f\"Number of different occupations in the dataset: {num_occupations}\")\n\nNumber of different occupations in the dataset: 21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nmost_frequent_occupation = users['occupation'].mode()[0]\n\n\nprint(f\"The most frequent occupation in the dataset is: {most_frequent_occupation}\")\n\nThe most frequent occupation in the dataset is: student\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nprint(users.describe())\n\n              age\ncount  943.000000\nmean    34.051962\nstd     12.192740\nmin      7.000000\n25%     25.000000\n50%     31.000000\n75%     43.000000\nmax     73.000000\n\n\n\nprint(users.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 943 entries, 1 to 943\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   age         943 non-null    int64 \n 1   gender      943 non-null    object\n 2   occupation  943 non-null    object\n 3   zip_code    943 non-null    object\ndtypes: int64(1), object(3)\nmemory usage: 36.8+ KB\nNone\n\n\n\n\nStep 15. Summarize all the columns\n\nsummary = users.describe(include='all').transpose()\n\n\nprint(summary)\n\n\n\n            count unique      top freq       mean       std  min   25%   50%  \\\nage         943.0    NaN      NaN  NaN  34.051962  12.19274  7.0  25.0  31.0   \ngender        943      2        M  670        NaN       NaN  NaN   NaN   NaN   \noccupation    943     21  student  196        NaN       NaN  NaN   NaN   NaN   \nzip_code      943    795    55414    9        NaN       NaN  NaN   NaN   NaN   \n\n             75%   max  \nage         43.0  73.0  \ngender       NaN   NaN  \noccupation   NaN   NaN  \nzip_code     NaN   NaN  \n\n\n\n\nStep 16. Summarize only the occupation column\n\noccupation_summary = users['occupation'].describe()\n\nprint(occupation_summary)\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nmean_age = users['age'].mean()\n\nprint(f\"The mean age of users is: {mean_age}\")\n\nThe mean age of users is: 34.05196182396607\n\n\n\n\nStep 18. What is the age with least occurrence?\n\n\nage_counts = users['age'].value_counts()\n\n\nleast_occurrence_ages = age_counts[age_counts == 1]\n\n\nleast_occurrence_ages.name = 'age'\n\n\nprint(least_occurrence_ages)\n\n\n\n\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: age, dtype: int64"
  },
  {
    "objectID": "docs/labs/Labexercises/Scores.out.html",
    "href": "docs/labs/Labexercises/Scores.out.html",
    "title": "Scores",
    "section": "",
    "text": "Introduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\n\ndata = {\n    'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'],\n    'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'],\n    'age': [42, 52, 36, 24, 73],\n    'female': [0, 1, 1, 0, 1],\n    'preTestScore': [4, 24, 31, 2, 3],\n    'postTestScore': [25, 94, 57, 62, 70]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n  first_name last_name  age  female  preTestScore  postTestScore\n0      Jason    Miller   42       0             4             25\n1      Molly  Jacobson   52       1            24             94\n2       Tina       Ali   36       1            31             57\n3       Jake    Milner   24       0             2             62\n4        Amy     Cooze   73       1             3             70\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df['preTestScore'], df['postTestScore'], s=df['age'], alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\n\nplt.scatter(df['preTestScore'], df['postTestScore'], \n            s=4.5 * df['postTestScore'], c=df['female'], cmap='coolwarm', alpha=0.5)\n\nplt.xlabel('Pre Test Score')\nplt.ylabel('Post Test Score')\nplt.title('Pre Test Score vs Post Test Score with Size and Color')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBONUS: Create your own question and answer it.\nFind the correlation between preTestScore and postTestScore\n\ncorrelation = df['preTestScore'].corr(df['postTestScore'])\nprint(f\"Correlation between preTestScore and postTestScore: {correlation}\")\n\nCorrelation between preTestScore and postTestScore: 0.37803911777651406"
  },
  {
    "objectID": "docs/labs/Practice/practice--2xujin.out.html",
    "href": "docs/labs/Practice/practice--2xujin.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\n\n\nimport matplotlib as mpl\n\n\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\n\n\nfrom pathlib import Path\n\n\nimport pingouin as pg\n\n\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\nfile_path = '游戏.xlsx'\ndf = pd.read_excel(file_path, header=1)\n\n\ndf.columns = df.columns.str.strip()\n\n\nfile_path = '游戏.xlsx'\ndf = pd.read_excel(file_path, header=0)\n\n\ndf.columns = ['Round_Label', 'Round_10', 'Round_9', 'Round_8', 'Round_7', 'Round_6', 'Round_5', 'Round_4', 'Round_3', 'Round_2', 'Round_1']\nround_data = df.iloc[1, 1:]\nround_numbers = list(range(1, 11))\n\n\navg_contribution_df = pd.DataFrame({\n    'Round': round_numbers,\n    'Average Contribution': round_data.values\n})\n\n\nplt.figure(figsize=(10, 6))\nplt.plot(avg_contribution_df['Round'], avg_contribution_df['Average Contribution'], marker='o', linestyle='-', color='b')\nplt.title('Average Contribution Over Rounds')\nplt.xlabel('Round')\nplt.ylabel('Average Contribution')\nplt.grid(True)\nplt.xticks(round_numbers)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\navg_contribution_description = f\"\"\"\nAverage contributions have varied across the 10 rounds of the game. Here are the key observations:\n- Round 1: {avg_contribution_df.loc[avg_contribution_df['Round'] == 1, 'Average Contribution'].values[0]}\n- Round 10: {avg_contribution_df.loc[avg_contribution_df['Round'] == 10, 'Average Contribution'].values[0]}\n- Highest Average Contribution: {avg_contribution_df['Average Contribution'].max()} (Round {avg_contribution_df['Average Contribution'].idxmax() + 1})\n- Lowest Average Contribution: {avg_contribution_df['Average Contribution'].min()} (Round {avg_contribution_df['Average Contribution'].idxmin() + 1})\n\"\"\"\nprint(avg_contribution_description)\nplt.show()\n\n\nAverage contributions have varied across the 10 rounds of the game. Here are the key observations:\n- Round 1: 53.4\n- Round 10: 50\n- Highest Average Contribution: 58.4 (Round 9)\n- Lowest Average Contribution: 44.3 (Round 6)\n\n\n\n# Create a dictionary with the data in\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()"
  },
  {
    "objectID": "docs/labs/Practice/practice-3xujin.out.html",
    "href": "docs/labs/Practice/practice-3xujin.out.html",
    "title": "",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\n\n\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)"
  },
  {
    "objectID": "docs/labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets.out.html",
    "href": "docs/labs/Practice/practice4/4.IMDb-and-Douban-top-250-movie-datasets.out.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0"
  }
]